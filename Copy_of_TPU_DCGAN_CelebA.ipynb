{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_TPU_DCGAN_CelebA.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinyRyo/TPU/blob/master/Copy_of_TPU_DCGAN_CelebA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_lQNXfMYUni",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow2.0+Colab TPUによるDCGANのサンプル\n",
        "作成者：こしあん（koshian2）\n",
        "\n",
        "## CelebAのダウンロード\n",
        "コードは　https://gist.github.com/charlesreid1/4f3d676b33b95fce83af08e4ec261822　より\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udWFxlOvYPgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        " \n",
        "def download_file_from_google_drive(id, destination):\n",
        "    def get_confirm_token(response):\n",
        "        for key, value in response.cookies.items():\n",
        "            if key.startswith('download_warning'):\n",
        "                return value\n",
        " \n",
        "        return None\n",
        " \n",
        "    def save_response_content(response, destination):\n",
        "        CHUNK_SIZE = 32768\n",
        " \n",
        "        with open(destination, \"wb\") as f:\n",
        "            for chunk in response.iter_content(CHUNK_SIZE):\n",
        "                if chunk: # filter out keep-alive new chunks\n",
        "                    f.write(chunk)\n",
        " \n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        " \n",
        "    session = requests.Session()\n",
        " \n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        " \n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        " \n",
        "    save_response_content(response, destination)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqxdEl0wYa13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download_file_from_google_drive(\"0B7EVK8r0v71pZjFTYXZWM3FlRnM\", \"celebA.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq2fSvxiYcTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip celebA.zip > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFaQvds5Ydut",
        "colab_type": "text"
      },
      "source": [
        "CelebAのファイル数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sySpXrKYf_i",
        "colab_type": "code",
        "outputId": "4ba475a2-bc7f-42e2-fc2d-1f19b8092113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls img_align_celeba -U1 | wc -l"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "202599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWIpihuHY-Hl",
        "colab_type": "text"
      },
      "source": [
        "## TF2.0にアップデート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIFT_8WpY8jh",
        "colab_type": "code",
        "outputId": "7df6ee48-9935-4970-f29c-a8e10056df52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 72kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.34.2)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.18.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.29.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.2)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 32.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (47.1.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.10.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.6.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=9f6853b3608f5470da2d6d68a0b165727a020602fa0149faadd893543f6d79ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ScQSkgYkJg",
        "colab_type": "text"
      },
      "source": [
        "## TPU用の初期設定\n",
        "Strategyの初期化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK_RTnYOYmKi",
        "colab_type": "code",
        "outputId": "d2dfa9ef-13c6-4074-9078-9a469529f347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "# tpu用\n",
        "tpu_grpc_url = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"]\n",
        "tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n",
        "tf.config.experimental_connect_to_cluster(tpu_cluster_resolver) # TF2.0の場合、ここを追加\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver) # TF2.0の場合、今後experimentialが取れる可能性がある    \n",
        "strategy = tf.distribute.experimental.TPUStrategy(tpu_cluster_resolver)  # ここも同様"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.84.63.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.84.63.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajejj_m6Ynz7",
        "colab_type": "text"
      },
      "source": [
        "分散訓練用のデコレーター　詳細：https://blog.shikoan.com/distributed-train-decorator-in-tf20/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9qrAyLDYpxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from enum import Enum\n",
        "\n",
        "# Distribute trainingを楽にするためのデコレーター\n",
        "class Reduction(Enum):\n",
        "    NONE = 0\n",
        "    SUM = 1\n",
        "    MEAN = 2\n",
        "    CONCAT = 3\n",
        "\n",
        "def distrtibuted(*reduction_flags):\n",
        "    def _decorator(fun):\n",
        "        def per_replica_reduction(z, flag):\n",
        "            if flag == Reduction.NONE:\n",
        "                return z\n",
        "            elif flag == Reduction.SUM:\n",
        "                return strategy.reduce(tf.distribute.ReduceOp.SUM, z, axis=None)\n",
        "            elif flag == Reduction.MEAN:\n",
        "                return strategy.reduce(tf.distribute.ReduceOp.MEAN, z, axis=None)\n",
        "            elif flag == Reduction.CONCAT:\n",
        "                z_list = strategy.experimental_local_results(z)\n",
        "                return tf.concat(z_list, axis=0)\n",
        "            else:\n",
        "                raise NotImplementedError()\n",
        "\n",
        "        @tf.function\n",
        "        def _decorated_fun(*args, **kwargs):\n",
        "            fun_result = strategy.experimental_run_v2(fun, args=args, kwargs=kwargs)\n",
        "            if len(reduction_flags) == 0:\n",
        "                assert fun_result is None\n",
        "                return\n",
        "            elif len(reduction_flags) == 1:\n",
        "                assert type(fun_result) is not tuple and fun_redult is not None\n",
        "                return per_replica_reduction(fun_result, *reduction_flags)\n",
        "            else:\n",
        "                assert type(fun_result) is tuple\n",
        "                return tuple((per_replica_reduction(fr, rf) for fr, rf in zip(fun_result, reduction_flags)))\n",
        "        return _decorated_fun\n",
        "    return _decorator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbxhHOqAYuT0",
        "colab_type": "text"
      },
      "source": [
        "## メイン部分（DCGAN）\n",
        "ロードがポイントで、現状のTPUではファイルを逐次読み込めないためNumpy配列に変換する。ただし、uint8のNumpy配列にしても、CelebAでは2GBの壁が問題になる（TensorFlowのオブジェクトは1個あたり2GBの制限がある）。\n",
        "\n",
        "そのため、データを前後で分割し、2GB未満になるようにする。前をX1、後をX2として、(X1, X2)というデータセットを作り、個々のTPUデバイスの中でX1とX2を結合して訓練する。\n",
        "\n",
        "DCGANの設定は[論文](https://arxiv.org/abs/1511.06434)の通り。バッチサイズ1024で訓練可能。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvsgWnBEYvhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_celeba(batch_size):\n",
        "    # list_filesがTPUで使えないので一旦メモリにNumpy配列にキャッシュする\n",
        "    if not os.path.exists(\"image_cache.pkl\"):\n",
        "        image_paths = sorted(glob.glob(\"./img_align_celeba/*.jpg\"))\n",
        "        images = np.zeros((len(image_paths), 64, 64, 3), np.uint8)\n",
        "        print(\"Create image caches...\")\n",
        "        for i, path in tqdm(enumerate(image_paths)):\n",
        "            with Image.open(path) as img:\n",
        "                img = img.resize((64, 64), Image.LANCZOS)\n",
        "                images[i] = np.asarray(img, np.uint8)\n",
        "        with open(\"image_cache.pkl\", \"wb\") as fp:\n",
        "            pickle.dump(images, fp)\n",
        "    else:\n",
        "        with open(\"image_cache.pkl\", \"rb\") as fp:\n",
        "            images = pickle.load(fp)\n",
        "    \n",
        "    # さらにテンソルが2GBまでしか入らないため前後でデータを分割する（ちょっと頭おかしい）\n",
        "    split_n = images.shape[0] // 2\n",
        "    images1, images2 = images[:split_n], images[split_n:2 * split_n]\n",
        "    del images\n",
        "\n",
        "    def preprocess(img):\n",
        "        x = tf.cast(img, tf.float32) / 127.5 - 1.0  # [-1. 1]\n",
        "        return x\n",
        "    \n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images1, images2))\n",
        "    dataset = dataset.map(\n",
        "        lambda x1, x2: (preprocess(x1), preprocess(x2))\n",
        "    ).shuffle(4096).batch(batch_size//2).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def get_initializers():\n",
        "    return (tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), # conv initializer\n",
        "            tf.keras.initializers.RandomNormal(mean=1.0, stddev=0.02)) # bn gamma initializer\n",
        "\n",
        "def create_generator(ngf=128):\n",
        "    conv_initializer, bn_gamma_initializer = get_initializers()\n",
        "    \n",
        "    inputs = layers.Input((1, 1, 100))\n",
        "    for i, k in enumerate([8, 4, 2, 1]):\n",
        "        if i == 0:\n",
        "            x = layers.Conv2DTranspose(ngf * k, 4, strides=1, padding=\"valid\", use_bias=False,\n",
        "                                       kernel_initializer=conv_initializer)(inputs)\n",
        "        else:\n",
        "            x = layers.Conv2DTranspose(ngf * k, 4, strides=2, padding=\"same\", use_bias=False,\n",
        "                                       kernel_initializer=conv_initializer)(x)\n",
        "        x = layers.BatchNormalization(gamma_initializer=bn_gamma_initializer)(x)\n",
        "        x = layers.ReLU()(x)\n",
        "    x = layers.Conv2DTranspose(3, 4, strides=2, padding=\"same\", use_bias=False,\n",
        "                               kernel_initializer=conv_initializer)(x)\n",
        "    x = layers.Activation(\"tanh\")(x)\n",
        "    return tf.keras.models.Model(inputs, x)\n",
        "\n",
        "def create_discriminator(ndf=128):\n",
        "    conv_initializer, bn_gamma_initializer = get_initializers()\n",
        "\n",
        "    inputs = layers.Input((64, 64, 3))\n",
        "    x = inputs\n",
        "    for i, k in enumerate([1, 2, 4, 8]):\n",
        "        x = layers.Conv2D(ndf * k, 4, strides=2, padding=\"same\", use_bias=False,        \n",
        "                          kernel_initializer=conv_initializer)(x)                          \n",
        "        if i != 0:\n",
        "            x = layers.BatchNormalization(gamma_initializer=bn_gamma_initializer)(x)\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    return tf.keras.models.Model(inputs, x)\n",
        "\n",
        "### save image utils\n",
        "def make_grid(imgs, nrow, padding=0):\n",
        "    assert imgs.ndim == 4 and nrow > 0\n",
        "    batch, height, width, ch = imgs.shape\n",
        "    n = nrow * (batch // nrow + np.sign(batch % nrow))\n",
        "    ncol = n // nrow\n",
        "    pad = np.zeros((n - batch, height, width, ch), imgs.dtype)\n",
        "    x = np.concatenate([imgs, pad], axis=0)\n",
        "    # border padding if required\n",
        "    if padding > 0:\n",
        "        x = np.pad(x, ((0, 0), (0, padding), (0, padding), (0, 0)),\n",
        "                   \"constant\", constant_values=(0, 0))\n",
        "        height += padding\n",
        "        width += padding\n",
        "    x = x.reshape(ncol, nrow, height, width, ch)\n",
        "    x = x.transpose([0, 2, 1, 3, 4])  # (ncol, height, nrow, width, ch)\n",
        "    x = x.reshape(height * ncol, width * nrow, ch)\n",
        "    if padding > 0:\n",
        "        x = x[:(height * ncol - padding),:(width * nrow - padding),:]\n",
        "    return x\n",
        "\n",
        "def save_img(imgs, filepath, nrow, padding=0):\n",
        "    grid_img = make_grid(imgs, nrow, padding=padding)\n",
        "    grid_img = ((grid_img + 1.0) * 127.5).astype(np.uint8)\n",
        "    with Image.fromarray(grid_img) as img:\n",
        "        img.save(filepath)\n",
        "###\n",
        "\n",
        "\n",
        "def main():\n",
        "    batch_size = 1024\n",
        "    dataset = load_celeba(batch_size)\n",
        "    out_dir = \"celeba_out\"\n",
        "\n",
        "    with strategy.scope():\n",
        "        model_G = create_generator()\n",
        "        model_D = create_discriminator()\n",
        "        param_G = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
        "        param_D = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
        "\n",
        "        dataset = strategy.experimental_distribute_dataset(dataset)\n",
        "        loss_func = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "        @distrtibuted(Reduction.SUM, Reduction.SUM, Reduction.CONCAT)\n",
        "        def train_on_batch(real_img1, real_img2):\n",
        "            # concat x1, x2\n",
        "            real_img = tf.concat([real_img1, real_img2], axis=0)\n",
        "            # generate fake images\n",
        "            with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n",
        "                z = tf.random.normal(shape=(real_img.shape[0], 1, 1, 100))\n",
        "                fake_img = model_G(z)\n",
        "            # train discriminator\n",
        "            with d_tape:\n",
        "                fake_out = model_D(fake_img)\n",
        "                real_out = model_D(real_img)\n",
        "                d_loss = (loss_func(tf.zeros(shape=(z.shape[0], 1)), fake_out)\n",
        "                            + loss_func(tf.ones(shape=(z.shape[0], 1)), real_out)) / 2.0\n",
        "                d_loss = tf.reduce_sum(d_loss) * (1.0 / batch_size)\n",
        "            gradients = d_tape.gradient(d_loss, model_D.trainable_weights)\n",
        "            param_D.apply_gradients(zip(gradients, model_D.trainable_weights))\n",
        "            # train generator\n",
        "            with g_tape:\n",
        "                fake_out = model_D(fake_img)\n",
        "                g_loss = loss_func(tf.ones(shape=(z.shape[0], 1)), fake_out)\n",
        "                g_loss = tf.reduce_sum(g_loss) * (1.0 / batch_size)\n",
        "            gradients = g_tape.gradient(g_loss, model_G.trainable_weights)\n",
        "            param_G.apply_gradients(zip(gradients, model_G.trainable_weights))\n",
        "            return d_loss, g_loss, fake_img \n",
        "\n",
        "        for epoch in range(100): # 100 epoch訓練\n",
        "            with tqdm(dataset) as pbar:\n",
        "                pbar.set_description(f\"[Epoch {epoch}]\")\n",
        "                for step, (X1, X2) in enumerate(pbar):\n",
        "                    d_loss, g_loss, fake = train_on_batch(X1, X2)\n",
        "                    pbar.set_postfix({\"g_loss\": g_loss.numpy(), \"d_loss\": d_loss.numpy()})\n",
        "                    if step == 200000 // batch_size - 1:\n",
        "                        fake_img = fake # 末尾だと端数が出るため\n",
        "\n",
        "            # save output\n",
        "            if not os.path.exists(out_dir):\n",
        "                os.makedirs(out_dir)\n",
        "            file_path = out_dir+f\"/epoch_{epoch:04}.png\"\n",
        "            save_img(fake_img.numpy()[:64], file_path, 8)\n",
        "            \n",
        "            # 3エポックごとに画像表示\n",
        "            if epoch % 3 == 0:\n",
        "                with Image.open(file_path) as img:\n",
        "                    plt.imshow(np.asarray(img))\n",
        "                    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u2nQixmYzpY",
        "colab_type": "code",
        "outputId": "97b7fc99-6e3c-4209-ec16-3ed28f215d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0]: : 197it [00:44,  4.40it/s, g_loss=5.13, d_loss=0.123]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-4bbda32d701a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Epoch {epoch}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                     \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"g_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"d_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200000\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    <ipython-input-7-65715247abc4>:27 _decorated_fun  *\n        fun_result = strategy.experimental_run_v2(fun, args=args, kwargs=kwargs)\n    <ipython-input-2-4bbda32d701a>:126 train_on_batch  *\n        z = tf.random.normal(shape=(real_img.shape[0], 1, 1, 100))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/random_ops.py:87 random_normal  **\n        shape_tensor = tensor_util.shape_tensor(shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py:1015 shape_tensor\n        return ops.convert_to_tensor(shape, dtype=dtype, name=\"shape\")\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1341 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:321 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:262 constant\n        allow_broadcast=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:300 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py:547 make_tensor_proto\n        \"supported type.\" % (type(values), values))\n\n    TypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (None, 1, 1, 100). Consider casting elements to a supported type.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfmXQ-m_DuvT",
        "colab_type": "text"
      },
      "source": [
        "#確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvkEG8Y836BW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "cf8a515c-81e0-4ef4-a11f-359a2fa3c06d"
      },
      "source": [
        "with tqdm(dataset) as pbar:\n",
        "        pbar.set_description(f\"[Epoch {epoch}]\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9d7ba92fb0b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Epoch {epoch}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THLyivFk5a6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1024\n",
        "dataset = load_celeba(batch_size)\n",
        "out_dir = \"celeba_out\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx_XBYQh6MTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7da0a629-61ca-4c1b-dc4c-deaa80c0a8b4"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 64, 64, 3), (None, 64, 64, 3)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DkID4y64cVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(100): # 100 epoch訓練\n",
        "    with tqdm(dataset) as pbar:\n",
        "        pbar.set_description(f\"[Epoch {epoch}]\")\n",
        "        #print(epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U622zVOCDU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "    model_G = create_generator()\n",
        "    model_D = create_discriminator()\n",
        "    param_G = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
        "    param_D = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
        "\n",
        "    dataset = strategy.experimental_distribute_dataset(dataset)\n",
        "    loss_func = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuY106tzBwOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_on_batch(real_img1, real_img2):\n",
        "    # concat x1, x2\n",
        "    real_img = tf.concat([real_img1, real_img2], axis=0)\n",
        "    # generate fake images\n",
        "    with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n",
        "        z = tf.random.normal(shape=(real_img.shape[0], 1, 1, 100))\n",
        "        fake_img = model_G(z)\n",
        "    # train discriminator\n",
        "    with d_tape:\n",
        "        fake_out = model_D(fake_img)\n",
        "        real_out = model_D(real_img)\n",
        "        d_loss = (loss_func(tf.zeros(shape=(z.shape[0], 1)), fake_out)\n",
        "                    + loss_func(tf.ones(shape=(z.shape[0], 1)), real_out)) / 2.0\n",
        "        d_loss = tf.reduce_sum(d_loss) * (1.0 / batch_size)\n",
        "    gradients = d_tape.gradient(d_loss, model_D.trainable_weights)\n",
        "    param_D.apply_gradients(zip(gradients, model_D.trainable_weights))\n",
        "    # train generator\n",
        "    with g_tape:\n",
        "        fake_out = model_D(fake_img)\n",
        "        g_loss = loss_func(tf.ones(shape=(z.shape[0], 1)), fake_out)\n",
        "        g_loss = tf.reduce_sum(g_loss) * (1.0 / batch_size)\n",
        "    gradients = g_tape.gradient(g_loss, model_G.trainable_weights)\n",
        "    param_G.apply_gradients(zip(gradients, model_G.trainable_weights))\n",
        "    return d_loss, g_loss, fake_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHpaA0jD6hed",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6d90313-676f-4a90-eb62-c6c15ae52857"
      },
      "source": [
        "#@distrtibuted(Reduction.SUM, Reduction.SUM, Reduction.CONCAT)\n",
        "for epoch in range(100): # 100 epoch訓練\n",
        "    with tqdm(dataset) as pbar:\n",
        "        pbar.set_description(f\"[Epoch {epoch}]\")\n",
        "        for step, (X1, X2) in enumerate(pbar):\n",
        "            d_loss, g_loss, fake = train_on_batch(X1, X2)\n",
        "            pbar.set_postfix({\"g_loss\": g_loss.numpy(), \"d_loss\": d_loss.numpy()})\n",
        "            if step == 200000 // batch_size - 1:\n",
        "                fake_img = fake # 末尾だと端数が出るため"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0]: : 0it [00:02, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ConcatV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m         tld.op_callbacks, values, axis)\n\u001b[0m\u001b[1;32m   1173\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-455d6d0300d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Epoch {epoch}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"g_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"d_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200000\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-ab5fd521cece>\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(real_img1, real_img2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_img1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_img2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# concat x1, x2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mreal_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_img1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_img2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# generate fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0md_tape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mg_tape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1604\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[1;32m   1605\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1606\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m         return concat_v2_eager_fallback(\n\u001b[0;32m-> 1177\u001b[0;31m             values, axis, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   1178\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2_eager_fallback\u001b[0;34m(values, axis, name, ctx)\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \"'concat_v2' Op, not %r.\" % values)\n\u001b[1;32m   1208\u001b[0m   \u001b[0m_attr_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m   \u001b[0m_attr_Tidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, default_dtype)\u001b[0m\n\u001b[1;32m    261\u001b[0m       ret.append(\n\u001b[1;32m    262\u001b[0m           ops.convert_to_tensor(\n\u001b[0;32m--> 263\u001b[0;31m               t, dtype, preferred_dtype=default_dtype, ctx=ctx))\n\u001b[0m\u001b[1;32m    264\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                          as_ref=False):\n\u001b[1;32m    320\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (PerReplica:{\n  0: <tf.Tensor: shape=(64, 64, 64, 3), dtype=float32, numpy=\narray([[[[-0.92156863, -0.9607843 , -0.9843137 ],\n         [-0.9764706 , -0.99215686, -1.        ],\n         [-1.        , -0.9843137 , -0.96862745],\n         ...,\n         [-0.81960785, -0.81960785, -0.8745098 ],\n         [-0.8117647 , -0.8117647 , -0.81960785],\n         [-0.88235295, -0.8745098 , -0.8901961 ]],\n\n        [[-0.92156863, -0.9607843 , -0.9843137 ],\n         [-0.9764706 , -0.99215686, -1.        ],\n         [-1.        , -0.9843137 , -0.96862745],\n         ...,\n         [-0.81960785, -0.81960785, -0.8745098 ],\n         [-0.8117647 , -0.8117647 , -0.81960785],\n         [-0.88235295, -0.8745098 , -0.8901961 ]],\n\n        [[-0.9137255 , -0.9529412 , -0.9843137 ],\n         [-0.96862745, -0.99215686, -0.99215686],\n         [-1.        , -0.9843137 , -0.9607843 ],\n         ...,\n         [-0.81960785, -0.81960785, -0.8745098 ],\n         [-0.8117647 , -0.8117647 , -0.81960785],\n         [-0.88235295, -0.8745098 , -0.8901961 ]],\n\n        ...,\n\n        [[ 0.7882353 ,  0.24705887,  0.03529418],\n         [ 0.52156866,  0.00392163, -0.23137254],\n         [ 0.36470592, -0.1372549 , -0.38039213],\n         ...,\n         [-0.9137255 , -0.90588236, -0.96862745],\n         [ 0.20000005,  0.21568632,  0.12941182],\n         [ 0.6392157 ,  0.6313726 ,  0.5372549 ]],\n\n        [[ 0.58431375,  0.19215691,  0.01176476],\n         [ 0.36470592,  0.00392163, -0.17647058],\n         [ 0.3803922 ,  0.06666672, -0.12941176],\n         ...,\n         [-0.827451  , -0.8117647 , -0.88235295],\n         [ 0.3411765 ,  0.36470592,  0.27058828],\n         [ 0.6       ,  0.5921569 ,  0.49803925]],\n\n        [[ 0.4039216 ,  0.17647064,  0.04313731],\n         [ 0.41960788,  0.23921573,  0.11372554],\n         [ 0.5294118 ,  0.38823533,  0.27058828],\n         ...,\n         [-0.6627451 , -0.654902  , -0.7176471 ],\n         [ 0.5137255 ,  0.5294118 ,  0.4431373 ],\n         [ 0.5686275 ,  0.56078434,  0.4666667 ]]],\n\n\n       [[[ 0.7176471 ,  0.49803925,  0.41960788],\n         [ 0.7411765 ,  0.48235297,  0.47450984],\n         [ 0.67058825,  0.38823533,  0.30980396],\n         ...,\n         [-0.12941176, -0.34117645, -0.52156866],\n         [ 0.07450986, -0.10588235, -0.23921567],\n         [-0.6       , -0.654902  , -0.78039217]],\n\n        [[ 0.7176471 ,  0.49803925,  0.41960788],\n         [ 0.7411765 ,  0.48235297,  0.47450984],\n         [ 0.6784314 ,  0.38823533,  0.3176471 ],\n         ...,\n         [-0.1372549 , -0.35686272, -0.5294118 ],\n         [ 0.082353  , -0.10588235, -0.23137254],\n         [-0.5921569 , -0.654902  , -0.77254903]],\n\n        [[ 0.7176471 ,  0.49803925,  0.41960788],\n         [ 0.7411765 ,  0.48235297,  0.47450984],\n         [ 0.67058825,  0.38823533,  0.30980396],\n         ...,\n         [-0.15294117, -0.36470586, -0.54509807],\n         [ 0.09803927, -0.09019607, -0.2235294 ],\n         [-0.5921569 , -0.64705884, -0.77254903]],\n\n        ...,\n\n        [[ 0.2313726 , -0.08235294, -0.23137254],\n         [-0.03529412, -0.32549018, -0.4823529 ],\n         [-0.3098039 , -0.5764706 , -0.73333335],\n         ...,\n         [ 0.49803925,  0.27843142,  0.41176474],\n         [ 0.48235297,  0.24705887,  0.22352946],\n         [ 0.4431373 ,  0.12941182,  0.03529418]],\n\n        [[ 0.13725495, -0.20784312, -0.372549  ],\n         [-0.16862744, -0.4823529 , -0.6392157 ],\n         [-0.38039213, -0.64705884, -0.79607844],\n         ...,\n         [ 0.5921569 ,  0.3803922 ,  0.5372549 ],\n         [ 0.4666667 ,  0.22352946,  0.20000005],\n         [ 0.4666667 ,  0.15294123,  0.05098045]],\n\n        [[ 0.0196079 , -0.34117645, -0.5294118 ],\n         [-0.26274508, -0.58431375, -0.7647059 ],\n         [-0.21568626, -0.4823529 , -0.6392157 ],\n         ...,\n         [ 0.60784316,  0.39607847,  0.54509807],\n         [ 0.5058824 ,  0.26274514,  0.23921573],\n         [ 0.48235297,  0.17647064,  0.07450986]]],\n\n\n       [[[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [-0.9764706 , -0.96862745, -0.9607843 ],\n         [-0.96862745, -0.9764706 , -0.94509804],\n         [-0.9529412 , -0.96862745, -0.9529412 ]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [-0.9764706 , -0.96862745, -0.9607843 ],\n         [-0.96862745, -0.9764706 , -0.94509804],\n         [-0.9607843 , -0.9764706 , -0.9607843 ]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [-0.96862745, -0.96862745, -0.9607843 ],\n         [-0.96862745, -0.96862745, -0.94509804],\n         [-0.96862745, -0.9843137 , -0.9607843 ]],\n\n        ...,\n\n        [[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [ 0.8666667 ,  0.6392157 , -0.18431371],\n         [ 0.96862745,  0.7647059 , -0.06666666],\n         [ 1.        ,  0.8352941 ,  0.00392163]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [ 0.21568632, -0.09803921, -0.92941177],\n         [ 0.32549024,  0.0196079 , -0.8039216 ],\n         [ 0.4901961 ,  0.13725495, -0.6627451 ]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [ 0.39607847,  0.03529418, -0.8745098 ],\n         [ 0.30980396, -0.05882353, -0.9529412 ],\n         [ 0.254902  , -0.12156862, -0.99215686]]],\n\n\n       ...,\n\n\n       [[[ 0.8352941 ,  0.9137255 ,  0.99215686],\n         [ 0.84313726,  0.92156863,  1.        ],\n         [ 0.84313726,  0.8980392 ,  0.99215686],\n         ...,\n         [-0.09803921, -0.14509803,  0.16078436],\n         [-0.02745098, -0.12941176,  0.13725495],\n         [ 0.18431377,  0.05098045,  0.27058828]],\n\n        [[ 0.8352941 ,  0.9137255 ,  0.99215686],\n         [ 0.84313726,  0.92156863,  1.        ],\n         [ 0.84313726,  0.8980392 ,  0.99215686],\n         ...,\n         [-0.12941176, -0.16862744,  0.12941182],\n         [-0.03529412, -0.12941176,  0.13725495],\n         [ 0.12941182, -0.00392157,  0.21568632]],\n\n        [[ 0.827451  ,  0.90588236,  0.9843137 ],\n         [ 0.8352941 ,  0.9137255 ,  0.99215686],\n         [ 0.84313726,  0.8980392 ,  0.9843137 ],\n         ...,\n         [-0.15294117, -0.19215685,  0.10588241],\n         [-0.02745098, -0.12156862,  0.14509809],\n         [ 0.07450986, -0.05882353,  0.16078436]],\n\n        ...,\n\n        [[-0.8039216 , -0.78039217, -0.6627451 ],\n         [-0.81960785, -0.79607844, -0.6862745 ],\n         [-0.8352941 , -0.8039216 , -0.70980394],\n         ...,\n         [-0.7254902 , -0.7647059 , -0.7254902 ],\n         [-0.45098037, -0.49019605, -0.4352941 ],\n         [-0.12156862, -0.19999999, -0.1607843 ]],\n\n        [[-0.8039216 , -0.78039217, -0.6627451 ],\n         [-0.81960785, -0.79607844, -0.6862745 ],\n         [-0.8352941 , -0.8039216 , -0.70980394],\n         ...,\n         [-0.3333333 , -0.38039213, -0.34117645],\n         [-0.1372549 , -0.18431371, -0.14509803],\n         [-0.06666666, -0.15294117, -0.12156862]],\n\n        [[-0.8039216 , -0.78039217, -0.6627451 ],\n         [-0.8117647 , -0.7882353 , -0.67058825],\n         [-0.827451  , -0.79607844, -0.7019608 ],\n         ...,\n         [-0.29411763, -0.32549018, -0.31764704],\n         [-0.38039213, -0.42745095, -0.41960782],\n         [-0.19999999, -0.2862745 , -0.26274508]]],\n\n\n       [[[-0.11372548, -0.35686272, -0.58431375],\n         [-0.12156862, -0.36470586, -0.5921569 ],\n         [-0.12941176, -0.372549  , -0.6       ],\n         ...,\n         [ 0.03529418, -0.27843136, -0.58431375],\n         [ 0.082353  , -0.2862745 , -0.5686275 ],\n         [ 0.082353  , -0.29411763, -0.56078434]],\n\n        [[-0.10588235, -0.3490196 , -0.5764706 ],\n         [-0.11372548, -0.35686272, -0.58431375],\n         [-0.12156862, -0.36470586, -0.5921569 ],\n         ...,\n         [ 0.03529418, -0.27843136, -0.58431375],\n         [ 0.082353  , -0.2862745 , -0.5686275 ],\n         [ 0.082353  , -0.29411763, -0.56078434]],\n\n        [[-0.10588235, -0.3490196 , -0.5764706 ],\n         [-0.10588235, -0.3490196 , -0.5764706 ],\n         [-0.10588235, -0.3490196 , -0.5764706 ],\n         ...,\n         [ 0.04313731, -0.27843136, -0.5764706 ],\n         [ 0.082353  , -0.2862745 , -0.5686275 ],\n         [ 0.07450986, -0.29411763, -0.56078434]],\n\n        ...,\n\n        [[ 0.082353  , -0.67058825, -0.6862745 ],\n         [ 0.07450986, -0.5294118 , -0.5529412 ],\n         [-0.17647058, -0.56078434, -0.6156863 ],\n         ...,\n         [-0.27843136, -0.42745095, -0.73333335],\n         [-0.31764704, -0.40392154, -0.8117647 ],\n         [-0.27843136, -0.372549  , -0.7176471 ]],\n\n        [[-0.23137254, -0.69411767, -0.62352943],\n         [-0.19215685, -0.5529412 , -0.4588235 ],\n         [-0.372549  , -0.6313726 , -0.5058824 ],\n         ...,\n         [-0.26274508, -0.41176468, -0.7254902 ],\n         [-0.2862745 , -0.372549  , -0.7882353 ],\n         [-0.24705881, -0.3333333 , -0.73333335]],\n\n        [[-0.45098037, -0.67058825, -0.654902  ],\n         [-0.5058824 , -0.7019608 , -0.6313726 ],\n         [-0.41960782, -0.60784316, -0.49019605],\n         ...,\n         [-0.25490195, -0.40392154, -0.7176471 ],\n         [-0.27843136, -0.36470586, -0.77254903],\n         [-0.25490195, -0.34117645, -0.7647059 ]]],\n\n\n       [[[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 0.96862745,  0.96862745,  0.96862745],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  0.9843137 ,  0.99215686]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 0.84313726,  0.84313726,  0.84313726],\n         [ 0.92156863,  0.92156863,  0.92156863],\n         [ 0.99215686,  0.99215686,  0.99215686]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 0.5686275 ,  0.5686275 ,  0.5764706 ],\n         [ 0.7176471 ,  0.7176471 ,  0.70980394],\n         [ 0.8352941 ,  0.84313726,  0.8352941 ]],\n\n        ...,\n\n        [[ 0.70980394,  0.427451  ,  0.11372554],\n         [ 0.67058825,  0.37254906,  0.05882359],\n         [ 0.62352943,  0.2941177 , -0.03529412],\n         ...,\n         [ 0.17647064, -0.17647058, -0.36470586],\n         [ 0.22352946, -0.14509803, -0.3960784 ],\n         [ 0.32549024,  0.02745104, -0.20784312]],\n\n        [[ 0.6862745 ,  0.39607847,  0.07450986],\n         [ 0.6313726 ,  0.32549024, -0.00392157],\n         [ 0.5921569 ,  0.26274514, -0.0745098 ],\n         ...,\n         [ 0.19215691, -0.1607843 , -0.36470586],\n         [ 0.23921573, -0.12941176, -0.372549  ],\n         [ 0.20000005, -0.09803921, -0.3333333 ]],\n\n        [[ 0.654902  ,  0.34901965,  0.02745104],\n         [ 0.6       ,  0.27843142, -0.05882353],\n         [ 0.5764706 ,  0.23921573, -0.11372548],\n         ...,\n         [ 0.12941182, -0.2235294 , -0.4588235 ],\n         [ 0.3803922 ,  0.0196079 , -0.2235294 ],\n         [ 0.41960788,  0.12156868, -0.10588235]]]], dtype=float32)>,\n  1: <tf.Tensor: shape=(64, 64, 64, 3), dtype=float32, numpy=\narray([[[[ 0.13725495,  0.14509809,  0.0196079 ],\n         [ 0.14509809,  0.15294123,  0.02745104],\n         [ 0.14509809,  0.15294123,  0.02745104],\n         ...,\n         [ 0.5921569 ,  0.5372549 ,  0.23921573],\n         [ 0.26274514,  0.22352946, -0.02745098],\n         [ 0.27058828,  0.27843142,  0.17647064]],\n\n        [[ 0.15294123,  0.16078436,  0.03529418],\n         [ 0.10588241,  0.11372554, -0.01176471],\n         [ 0.11372554,  0.12156868, -0.00392157],\n         ...,\n         [ 0.48235297,  0.43529415,  0.16078436],\n         [ 0.20784318,  0.1686275 , -0.02745098],\n         [ 0.2941177 ,  0.30196083,  0.21568632]],\n\n        [[ 0.1686275 ,  0.17647064,  0.05098045],\n         [ 0.12156868,  0.12941182,  0.00392163],\n         [ 0.09803927,  0.10588241, -0.01960784],\n         ...,\n         [ 0.27058828,  0.22352946, -0.00392157],\n         [ 0.27843142,  0.26274514,  0.13725495],\n         [ 0.26274514,  0.27843142,  0.20784318]],\n\n        ...,\n\n        [[ 0.3411765 ,  0.24705887,  0.11372554],\n         [ 0.36470592,  0.22352946,  0.10588241],\n         [ 0.4039216 ,  0.20000005,  0.09803927],\n         ...,\n         [ 0.8039216 ,  0.8039216 ,  0.7882353 ],\n         [ 0.77254903,  0.8117647 ,  0.7882353 ],\n         [ 0.6627451 ,  0.67058825,  0.6       ]],\n\n        [[ 0.3411765 ,  0.19215691,  0.07450986],\n         [ 0.3411765 ,  0.15294123,  0.06666672],\n         [ 0.28627455,  0.06666672,  0.02745104],\n         ...,\n         [ 0.7490196 ,  0.7647059 ,  0.827451  ],\n         [ 0.7490196 ,  0.77254903,  0.8117647 ],\n         [ 0.70980394,  0.7176471 ,  0.7019608 ]],\n\n        [[ 0.30196083,  0.082353  , -0.00392157],\n         [ 0.28627455,  0.05882359,  0.01176476],\n         [ 0.3176471 ,  0.10588241,  0.11372554],\n         ...,\n         [ 0.73333335,  0.7647059 ,  0.8666667 ],\n         [ 0.7411765 ,  0.7411765 ,  0.8352941 ],\n         [ 0.7490196 ,  0.7490196 ,  0.7882353 ]]],\n\n\n       [[[-0.21568626, -0.34117645, -0.52156866],\n         [-0.25490195, -0.38039213, -0.5764706 ],\n         [-0.26274508, -0.38823527, -0.6       ],\n         ...,\n         [-0.7411765 , -0.88235295, -0.9764706 ],\n         [-0.77254903, -0.9137255 , -0.9843137 ],\n         [-0.8352941 , -0.9843137 , -0.99215686]],\n\n        [[-0.01960784, -0.14509803, -0.38823527],\n         [-0.09803921, -0.21568626, -0.45098037],\n         [-0.18431371, -0.30196077, -0.5294118 ],\n         ...,\n         [-0.7490196 , -0.8901961 , -0.9764706 ],\n         [-0.8117647 , -0.9607843 , -1.        ],\n         [-0.827451  , -0.96862745, -1.        ]],\n\n        [[ 0.082353  , -0.02745098, -0.3098039 ],\n         [ 0.09019613, -0.02745098, -0.2862745 ],\n         [ 0.04313731, -0.0745098 , -0.3098039 ],\n         ...,\n         [-0.7647059 , -0.90588236, -0.96862745],\n         [-0.8352941 , -0.9843137 , -1.        ],\n         [-0.79607844, -0.9372549 , -1.        ]],\n\n        ...,\n\n        [[-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         ...,\n         [-0.88235295, -0.9372549 , -0.9137255 ],\n         [-0.84313726, -0.8980392 , -0.8745098 ],\n         [-0.827451  , -0.90588236, -0.85882354]],\n\n        [[-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         ...,\n         [-0.9372549 , -0.9843137 , -0.9764706 ],\n         [-0.9529412 , -0.99215686, -0.9843137 ],\n         [-0.8980392 , -0.96862745, -0.9372549 ]],\n\n        [[-0.9843137 , -0.9843137 , -0.9843137 ],\n         [-0.9843137 , -0.9843137 , -0.9843137 ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [-0.8745098 , -0.92156863, -0.90588236],\n         [-0.8901961 , -0.9372549 , -0.92156863],\n         [-0.90588236, -0.9764706 , -0.9529412 ]]],\n\n\n       [[[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 0.0196079 , -0.15294117, -0.52156866],\n         [ 0.01176476, -0.15294117, -0.52156866],\n         [ 0.0196079 , -0.15294117, -0.52156866]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 0.02745104, -0.14509803, -0.5137255 ],\n         [ 0.01176476, -0.15294117, -0.52156866],\n         [ 0.0196079 , -0.15294117, -0.52156866]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [ 0.02745104, -0.14509803, -0.5137255 ],\n         [ 0.00392163, -0.1607843 , -0.5294118 ],\n         [ 0.0196079 , -0.15294117, -0.52156866]],\n\n        ...,\n\n        [[-0.6313726 , -0.73333335, -0.8352941 ],\n         [-0.6784314 , -0.78039217, -0.88235295],\n         [-0.7254902 , -0.81960785, -0.9137255 ],\n         ...,\n         [-0.54509807, -0.6862745 , -0.78039217],\n         [-0.5686275 , -0.70980394, -0.8039216 ],\n         [-0.5921569 , -0.7176471 , -0.8117647 ]],\n\n        [[-0.6156863 , -0.7254902 , -0.827451  ],\n         [-0.6313726 , -0.7411765 , -0.84313726],\n         [-0.69411767, -0.7882353 , -0.88235295],\n         ...,\n         [-0.54509807, -0.6862745 , -0.78039217],\n         [-0.5686275 , -0.70980394, -0.8039216 ],\n         [-0.5921569 , -0.7176471 , -0.8117647 ]],\n\n        [[-0.58431375, -0.69411767, -0.79607844],\n         [-0.60784316, -0.7176471 , -0.81960785],\n         [-0.6627451 , -0.75686276, -0.85882354],\n         ...,\n         [-0.54509807, -0.6862745 , -0.78039217],\n         [-0.56078434, -0.7019608 , -0.79607844],\n         [-0.6       , -0.7176471 , -0.81960785]]],\n\n\n       ...,\n\n\n       [[[ 0.70980394,  0.6313726 ,  0.3411765 ],\n         [ 0.6784314 ,  0.60784316,  0.32549024],\n         [ 0.6862745 ,  0.6156863 ,  0.33333337],\n         ...,\n         [-0.73333335, -0.73333335, -0.75686276],\n         [-0.77254903, -0.8039216 , -0.79607844],\n         [-0.81960785, -0.88235295, -0.8745098 ]],\n\n        [[ 0.7176471 ,  0.4039216 ,  0.15294123],\n         [ 0.7490196 ,  0.4431373 ,  0.20000005],\n         [ 0.7490196 ,  0.4901961 ,  0.23921573],\n         ...,\n         [-0.7411765 , -0.7411765 , -0.77254903],\n         [-0.7882353 , -0.8117647 , -0.8039216 ],\n         [-0.827451  , -0.8901961 , -0.88235295]],\n\n        [[ 0.4901961 , -0.36470586, -0.4980392 ],\n         [ 0.52156866, -0.31764704, -0.45098037],\n         [ 0.5137255 , -0.27058822, -0.41176468],\n         ...,\n         [-0.7490196 , -0.7490196 , -0.78039217],\n         [-0.79607844, -0.827451  , -0.81960785],\n         [-0.84313726, -0.90588236, -0.8980392 ]],\n\n        ...,\n\n        [[-0.02745098, -0.03529412, -0.12941176],\n         [-0.14509803, -0.1372549 , -0.21568626],\n         [-0.1372549 , -0.12941176, -0.19215685],\n         ...,\n         [-0.01176471, -0.05882353, -0.20784312],\n         [ 0.14509809,  0.09019613, -0.06666666],\n         [ 0.00392163, -0.03529412, -0.1607843 ]],\n\n        [[-0.23137254, -0.2235294 , -0.32549018],\n         [-0.12156862, -0.12156862, -0.21568626],\n         [-0.12941176, -0.12941176, -0.20784312],\n         ...,\n         [ 0.20784318,  0.14509809, -0.01176471],\n         [ 0.20000005,  0.12941182, -0.03529412],\n         [ 0.10588241,  0.05098045, -0.10588235]],\n\n        [[-0.03529412, -0.02745098, -0.1372549 ],\n         [-0.02745098, -0.01960784, -0.12941176],\n         [-0.04313725, -0.05098039, -0.1372549 ],\n         ...,\n         [ 0.24705887,  0.1686275 ,  0.01176476],\n         [ 0.17647064,  0.09019613, -0.08235294],\n         [ 0.12941182,  0.07450986, -0.12941176]]],\n\n\n       [[[ 0.7647059 ,  0.827451  ,  0.84313726],\n         [ 0.7647059 ,  0.827451  ,  0.84313726],\n         [ 0.7647059 ,  0.827451  ,  0.8509804 ],\n         ...,\n         [ 0.7647059 ,  0.8039216 ,  0.827451  ],\n         [ 0.78039217,  0.81960785,  0.84313726],\n         [ 0.77254903,  0.8117647 ,  0.84313726]],\n\n        [[ 0.7647059 ,  0.827451  ,  0.84313726],\n         [ 0.7647059 ,  0.827451  ,  0.84313726],\n         [ 0.7647059 ,  0.827451  ,  0.8509804 ],\n         ...,\n         [ 0.7647059 ,  0.8039216 ,  0.827451  ],\n         [ 0.78039217,  0.81960785,  0.84313726],\n         [ 0.77254903,  0.8117647 ,  0.84313726]],\n\n        [[ 0.7647059 ,  0.827451  ,  0.84313726],\n         [ 0.7647059 ,  0.827451  ,  0.84313726],\n         [ 0.7647059 ,  0.827451  ,  0.8509804 ],\n         ...,\n         [ 0.77254903,  0.8117647 ,  0.8352941 ],\n         [ 0.78039217,  0.81960785,  0.84313726],\n         [ 0.77254903,  0.8117647 ,  0.84313726]],\n\n        ...,\n\n        [[ 0.22352946, -0.01960784, -0.14509803],\n         [ 0.3176471 ,  0.12941182, -0.14509803],\n         [ 0.3803922 ,  0.20784318, -0.12941176],\n         ...,\n         [ 0.427451  ,  0.17647064, -0.08235294],\n         [ 0.37254906, -0.05098039, -0.4352941 ],\n         [ 0.3411765 , -0.09803921, -0.4980392 ]],\n\n        [[ 0.17647064, -0.09803921, -0.27058822],\n         [ 0.18431377, -0.0745098 , -0.38823527],\n         [ 0.27843142,  0.02745104, -0.3490196 ],\n         ...,\n         [ 0.7019608 ,  0.5764706 ,  0.33333337],\n         [ 0.37254906,  0.09019613, -0.29411763],\n         [ 0.34901965,  0.01176476, -0.38823527]],\n\n        [[-0.02745098, -0.32549018, -0.5529412 ],\n         [ 0.12941182, -0.16862744, -0.5294118 ],\n         [ 0.05098045, -0.27843136, -0.6627451 ],\n         ...,\n         [ 0.827451  ,  0.79607844,  0.5294118 ],\n         [ 0.45882356,  0.3176471 , -0.08235294],\n         [ 0.38823533,  0.12156868, -0.29411763]]],\n\n\n       [[[ 0.6       ,  0.5921569 ,  0.56078434],\n         [ 0.60784316,  0.6       ,  0.5686275 ],\n         [ 0.62352943,  0.6156863 ,  0.58431375],\n         ...,\n         [ 0.73333335,  0.7019608 ,  0.6784314 ],\n         [ 0.73333335,  0.7019608 ,  0.6784314 ],\n         [ 0.73333335,  0.7019608 ,  0.6784314 ]],\n\n        [[ 0.6       ,  0.5921569 ,  0.56078434],\n         [ 0.60784316,  0.6       ,  0.5686275 ],\n         [ 0.62352943,  0.6156863 ,  0.58431375],\n         ...,\n         [ 0.73333335,  0.7019608 ,  0.6784314 ],\n         [ 0.73333335,  0.7019608 ,  0.6784314 ],\n         [ 0.7254902 ,  0.69411767,  0.67058825]],\n\n        [[ 0.6       ,  0.5921569 ,  0.56078434],\n         [ 0.60784316,  0.6       ,  0.5686275 ],\n         [ 0.62352943,  0.6156863 ,  0.58431375],\n         ...,\n         [ 0.7254902 ,  0.69411767,  0.67058825],\n         [ 0.7254902 ,  0.69411767,  0.67058825],\n         [ 0.7254902 ,  0.69411767,  0.67058825]],\n\n        ...,\n\n        [[ 0.75686276,  0.7254902 ,  0.7019608 ],\n         [ 0.7490196 ,  0.7176471 ,  0.69411767],\n         [ 0.7490196 ,  0.7176471 ,  0.69411767],\n         ...,\n         [ 0.3803922 ,  0.07450986, -0.1372549 ],\n         [ 0.6313726 ,  0.19215691, -0.10588235],\n         [ 0.5764706 ,  0.13725495, -0.1607843 ]],\n\n        [[ 0.01176476,  0.03529418, -0.00392157],\n         [-0.05882353, -0.03529412, -0.0745098 ],\n         [-0.09019607, -0.06666666, -0.11372548],\n         ...,\n         [ 0.5294118 ,  0.19215691, -0.03529412],\n         [ 0.58431375,  0.15294123, -0.12941176],\n         [ 0.6       ,  0.1686275 , -0.12941176]],\n\n        [[-0.81960785, -0.7647059 , -0.81960785],\n         [-0.8509804 , -0.79607844, -0.8509804 ],\n         [-0.8745098 , -0.81960785, -0.8745098 ],\n         ...,\n         [ 0.4901961 ,  0.13725495, -0.10588235],\n         [ 0.6156863 ,  0.20000005, -0.09019607],\n         [ 0.60784316,  0.17647064, -0.12156862]]]], dtype=float32)>,\n  2: <tf.Tensor: shape=(64, 64, 64, 3), dtype=float32, numpy=\narray([[[[ 0.6156863 ,  0.6313726 ,  0.60784316],\n         [ 0.6156863 ,  0.6313726 ,  0.60784316],\n         [ 0.6156863 ,  0.6313726 ,  0.60784316],\n         ...,\n         [ 0.4039216 ,  0.4039216 ,  0.38823533],\n         [ 0.4039216 ,  0.4039216 ,  0.38823533],\n         [ 0.4039216 ,  0.4039216 ,  0.38823533]],\n\n        [[ 0.6156863 ,  0.6313726 ,  0.60784316],\n         [ 0.6156863 ,  0.6313726 ,  0.60784316],\n         [ 0.6156863 ,  0.6313726 ,  0.60784316],\n         ...,\n         [ 0.4039216 ,  0.4039216 ,  0.38823533],\n         [ 0.4039216 ,  0.4039216 ,  0.38823533],\n         [ 0.4039216 ,  0.4039216 ,  0.38823533]],\n\n        [[ 0.6156863 ,  0.6313726 ,  0.60784316],\n         [ 0.6156863 ,  0.6313726 ,  0.60784316],\n         [ 0.6156863 ,  0.6313726 ,  0.60784316],\n         ...,\n         [ 0.4039216 ,  0.4039216 ,  0.38823533],\n         [ 0.4039216 ,  0.4039216 ,  0.38823533],\n         [ 0.4039216 ,  0.4039216 ,  0.38823533]],\n\n        ...,\n\n        [[-0.1372549 , -0.17647058, -0.20784312],\n         [-0.1372549 , -0.17647058, -0.20784312],\n         [-0.1372549 , -0.17647058, -0.20784312],\n         ...,\n         [ 0.64705884,  0.6627451 ,  0.6392157 ],\n         [ 0.64705884,  0.6627451 ,  0.6392157 ],\n         [ 0.64705884,  0.6627451 ,  0.6392157 ]],\n\n        [[-0.1372549 , -0.17647058, -0.20784312],\n         [-0.1372549 , -0.17647058, -0.20784312],\n         [-0.1372549 , -0.17647058, -0.20784312],\n         ...,\n         [ 0.64705884,  0.6627451 ,  0.6392157 ],\n         [ 0.64705884,  0.6627451 ,  0.6392157 ],\n         [ 0.64705884,  0.6627451 ,  0.6392157 ]],\n\n        [[-0.1372549 , -0.17647058, -0.20784312],\n         [-0.1372549 , -0.17647058, -0.20784312],\n         [-0.1372549 , -0.17647058, -0.20784312],\n         ...,\n         [ 0.64705884,  0.6627451 ,  0.6392157 ],\n         [ 0.64705884,  0.6627451 ,  0.6392157 ],\n         [ 0.64705884,  0.6627451 ,  0.6392157 ]]],\n\n\n       [[[-0.75686276, -0.8039216 , -0.8039216 ],\n         [-0.75686276, -0.8039216 , -0.8039216 ],\n         [-0.75686276, -0.8039216 , -0.8039216 ],\n         ...,\n         [ 0.01176476, -0.08235294, -0.25490195],\n         [-0.01176471, -0.09803921, -0.29411763],\n         [-0.01960784, -0.09019607, -0.3098039 ]],\n\n        [[-0.75686276, -0.8039216 , -0.8039216 ],\n         [-0.75686276, -0.8039216 , -0.8039216 ],\n         [-0.75686276, -0.8039216 , -0.8039216 ],\n         ...,\n         [ 0.01176476, -0.08235294, -0.25490195],\n         [-0.01176471, -0.09803921, -0.29411763],\n         [-0.01960784, -0.09019607, -0.3098039 ]],\n\n        [[-0.75686276, -0.8039216 , -0.8039216 ],\n         [-0.75686276, -0.8039216 , -0.8039216 ],\n         [-0.75686276, -0.8039216 , -0.8039216 ],\n         ...,\n         [ 0.00392163, -0.09019607, -0.26274508],\n         [-0.01176471, -0.09803921, -0.29411763],\n         [-0.01960784, -0.09019607, -0.3098039 ]],\n\n        ...,\n\n        [[-0.77254903, -0.8117647 , -0.8352941 ],\n         [-0.77254903, -0.8117647 , -0.827451  ],\n         [-0.78039217, -0.8117647 , -0.81960785],\n         ...,\n         [-0.2862745 , -0.5686275 , -0.6784314 ],\n         [-0.18431371, -0.5372549 , -0.6862745 ],\n         [-0.15294117, -0.5294118 , -0.69411767]],\n\n        [[-0.77254903, -0.8117647 , -0.81960785],\n         [-0.78039217, -0.8117647 , -0.81960785],\n         [-0.78039217, -0.8117647 , -0.81960785],\n         ...,\n         [ 0.0196079 , -0.26274508, -0.38039213],\n         [-0.19215685, -0.5372549 , -0.70980394],\n         [-0.17647058, -0.54509807, -0.7254902 ]],\n\n        [[-0.78039217, -0.8117647 , -0.8117647 ],\n         [-0.78039217, -0.8117647 , -0.81960785],\n         [-0.75686276, -0.8039216 , -0.81960785],\n         ...,\n         [ 0.45098042,  0.15294123,  0.0196079 ],\n         [ 0.2941177 , -0.0745098 , -0.26274508],\n         [ 0.03529418, -0.34117645, -0.5372549 ]]],\n\n\n       [[[ 0.35686278,  0.41960788,  0.5686275 ],\n         [ 0.35686278,  0.41960788,  0.5686275 ],\n         [ 0.35686278,  0.41960788,  0.5686275 ],\n         ...,\n         [ 0.49803925,  0.5686275 ,  0.7019608 ],\n         [ 0.49803925,  0.5686275 ,  0.7019608 ],\n         [ 0.4901961 ,  0.56078434,  0.69411767]],\n\n        [[ 0.35686278,  0.41960788,  0.5686275 ],\n         [ 0.35686278,  0.41960788,  0.5686275 ],\n         [ 0.35686278,  0.41960788,  0.5686275 ],\n         ...,\n         [ 0.49803925,  0.5686275 ,  0.7019608 ],\n         [ 0.49803925,  0.5686275 ,  0.7019608 ],\n         [ 0.4901961 ,  0.56078434,  0.69411767]],\n\n        [[ 0.35686278,  0.41960788,  0.5686275 ],\n         [ 0.35686278,  0.41960788,  0.5686275 ],\n         [ 0.35686278,  0.41960788,  0.5686275 ],\n         ...,\n         [ 0.49803925,  0.5686275 ,  0.7019608 ],\n         [ 0.49803925,  0.5686275 ,  0.7019608 ],\n         [ 0.4901961 ,  0.56078434,  0.69411767]],\n\n        ...,\n\n        [[ 0.19215691,  0.3176471 ,  0.52156866],\n         [ 0.20000005,  0.3176471 ,  0.52156866],\n         [ 0.20784318,  0.3176471 ,  0.52156866],\n         ...,\n         [ 0.41176474,  0.48235297,  0.6156863 ],\n         [ 0.41176474,  0.48235297,  0.6156863 ],\n         [ 0.4039216 ,  0.47450984,  0.60784316]],\n\n        [[ 0.20784318,  0.33333337,  0.5372549 ],\n         [ 0.20784318,  0.33333337,  0.5372549 ],\n         [ 0.21568632,  0.34901965,  0.5529412 ],\n         ...,\n         [ 0.4039216 ,  0.47450984,  0.60784316],\n         [ 0.4039216 ,  0.47450984,  0.60784316],\n         [ 0.4039216 ,  0.47450984,  0.60784316]],\n\n        [[ 0.18431377,  0.3176471 ,  0.5137255 ],\n         [ 0.11372554,  0.27843142,  0.4901961 ],\n         [-0.03529412,  0.14509809,  0.37254906],\n         ...,\n         [ 0.38823533,  0.45882356,  0.5921569 ],\n         [ 0.38823533,  0.45882356,  0.5921569 ],\n         [ 0.38823533,  0.45882356,  0.5921569 ]]],\n\n\n       ...,\n\n\n       [[[-0.7176471 , -0.81960785, -0.88235295],\n         [-0.7176471 , -0.81960785, -0.88235295],\n         [-0.7176471 , -0.81960785, -0.88235295],\n         ...,\n         [-0.5921569 , -0.7647059 , -0.84313726],\n         [-0.5764706 , -0.75686276, -0.827451  ],\n         [-0.5686275 , -0.75686276, -0.827451  ]],\n\n        [[-0.7176471 , -0.81960785, -0.88235295],\n         [-0.7176471 , -0.81960785, -0.88235295],\n         [-0.7176471 , -0.81960785, -0.88235295],\n         ...,\n         [-0.6392157 , -0.7882353 , -0.8509804 ],\n         [-0.62352943, -0.78039217, -0.84313726],\n         [-0.6392157 , -0.77254903, -0.84313726]],\n\n        [[-0.7254902 , -0.81960785, -0.88235295],\n         [-0.7254902 , -0.81960785, -0.88235295],\n         [-0.7254902 , -0.81960785, -0.88235295],\n         ...,\n         [-0.7019608 , -0.827451  , -0.8745098 ],\n         [-0.69411767, -0.827451  , -0.8745098 ],\n         [-0.7254902 , -0.81960785, -0.8666667 ]],\n\n        ...,\n\n        [[-0.827451  , -0.827451  , -0.827451  ],\n         [-0.827451  , -0.827451  , -0.827451  ],\n         [-0.827451  , -0.827451  , -0.827451  ],\n         ...,\n         [-0.8352941 , -0.84313726, -0.85882354],\n         [-0.8352941 , -0.84313726, -0.85882354],\n         [-0.8352941 , -0.84313726, -0.85882354]],\n\n        [[-0.827451  , -0.827451  , -0.827451  ],\n         [-0.827451  , -0.827451  , -0.827451  ],\n         [-0.827451  , -0.827451  , -0.827451  ],\n         ...,\n         [-0.8352941 , -0.84313726, -0.85882354],\n         [-0.8352941 , -0.84313726, -0.85882354],\n         [-0.8352941 , -0.84313726, -0.85882354]],\n\n        [[-0.827451  , -0.827451  , -0.827451  ],\n         [-0.827451  , -0.827451  , -0.827451  ],\n         [-0.827451  , -0.827451  , -0.827451  ],\n         ...,\n         [-0.8352941 , -0.84313726, -0.85882354],\n         [-0.8352941 , -0.84313726, -0.85882354],\n         [-0.8352941 , -0.84313726, -0.85882354]]],\n\n\n       [[[-0.1607843 , -0.17647058, -0.24705881],\n         [-0.11372548, -0.12156862, -0.16862744],\n         [ 0.20784318,  0.20784318,  0.19215691],\n         ...,\n         [-0.24705881, -0.26274508, -0.27058822],\n         [-0.35686272, -0.41176468, -0.44313723],\n         [-0.47450978, -0.5058824 , -0.5372549 ]],\n\n        [[-0.29411763, -0.40392154, -0.44313723],\n         [-0.3098039 , -0.40392154, -0.42745095],\n         [-0.35686272, -0.40392154, -0.40392154],\n         ...,\n         [-0.25490195, -0.27843136, -0.27843136],\n         [-0.56078434, -0.6156863 , -0.6392157 ],\n         [-0.60784316, -0.6784314 , -0.69411767]],\n\n        [[-0.19215685, -0.35686272, -0.372549  ],\n         [-0.20784312, -0.34117645, -0.34117645],\n         [-0.34117645, -0.41960782, -0.41176468],\n         ...,\n         [-0.27058822, -0.29411763, -0.29411763],\n         [-0.6       , -0.654902  , -0.6784314 ],\n         [-0.67058825, -0.7647059 , -0.7647059 ]],\n\n        ...,\n\n        [[-0.09803921, -0.09019607,  0.01176476],\n         [-0.06666666, -0.05882353,  0.02745104],\n         [-0.05882353, -0.04313725,  0.01176476],\n         ...,\n         [-0.64705884, -0.6627451 , -0.69411767],\n         [-0.6313726 , -0.6392157 , -0.6784314 ],\n         [-0.6313726 , -0.654902  , -0.69411767]],\n\n        [[-0.12156862, -0.12156862, -0.04313725],\n         [-0.2862745 , -0.29411763, -0.2235294 ],\n         [-0.44313723, -0.44313723, -0.40392154],\n         ...,\n         [-0.60784316, -0.6156863 , -0.64705884],\n         [-0.64705884, -0.654902  , -0.6862745 ],\n         [-0.67058825, -0.69411767, -0.7176471 ]],\n\n        [[-0.47450978, -0.4823529 , -0.44313723],\n         [-0.4823529 , -0.4823529 , -0.45098037],\n         [-0.372549  , -0.372549  , -0.3490196 ],\n         ...,\n         [-0.4588235 , -0.46666664, -0.4823529 ],\n         [-0.52156866, -0.5294118 , -0.54509807],\n         [-0.5764706 , -0.6       , -0.60784316]]],\n\n\n       [[[-0.35686272, -0.32549018, -0.30196077],\n         [-0.20784312, -0.17647058, -0.15294117],\n         [-0.24705881, -0.20784312, -0.18431371],\n         ...,\n         [-0.27843136, -0.24705881, -0.2235294 ],\n         [-0.29411763, -0.26274508, -0.23921567],\n         [-0.35686272, -0.31764704, -0.29411763]],\n\n        [[-0.3098039 , -0.27843136, -0.25490195],\n         [-0.19215685, -0.1607843 , -0.1372549 ],\n         [-0.2862745 , -0.23921567, -0.2235294 ],\n         ...,\n         [-0.25490195, -0.2235294 , -0.19999999],\n         [-0.3333333 , -0.30196077, -0.27843136],\n         [-0.3490196 , -0.3098039 , -0.2862745 ]],\n\n        [[-0.25490195, -0.2235294 , -0.19999999],\n         [-0.20784312, -0.17647058, -0.15294117],\n         [-0.31764704, -0.27843136, -0.25490195],\n         ...,\n         [-0.25490195, -0.2235294 , -0.19999999],\n         [-0.35686272, -0.32549018, -0.30196077],\n         [-0.3490196 , -0.3098039 , -0.2862745 ]],\n\n        ...,\n\n        [[-0.69411767, -0.654902  , -0.6313726 ],\n         [-0.69411767, -0.654902  , -0.6313726 ],\n         [-0.7411765 , -0.7019608 , -0.6784314 ],\n         ...,\n         [-0.7647059 , -0.7411765 , -0.7019608 ],\n         [-0.45098037, -0.42745095, -0.38823527],\n         [-0.52156866, -0.4823529 , -0.45098037]],\n\n        [[-0.70980394, -0.67058825, -0.64705884],\n         [-0.7254902 , -0.6862745 , -0.6627451 ],\n         [-0.7411765 , -0.7019608 , -0.6784314 ],\n         ...,\n         [-0.81960785, -0.7882353 , -0.75686276],\n         [-0.45098037, -0.42745095, -0.38823527],\n         [-0.56078434, -0.52156866, -0.49019605]],\n\n        [[-0.7019608 , -0.6627451 , -0.6392157 ],\n         [-0.7176471 , -0.6784314 , -0.654902  ],\n         [-0.6784314 , -0.6392157 , -0.6156863 ],\n         ...,\n         [-0.92156863, -0.8901961 , -0.85882354],\n         [-0.5529412 , -0.5294118 , -0.49019605],\n         [-0.42745095, -0.38823527, -0.35686272]]]], dtype=float32)>,\n  3: <tf.Tensor: shape=(64, 64, 64, 3), dtype=float32, numpy=\narray([[[[-0.79607844, -0.8352941 , -0.7882353 ],\n         [-0.8039216 , -0.84313726, -0.79607844],\n         [-0.8117647 , -0.8509804 , -0.8039216 ],\n         ...,\n         [-0.73333335, -0.8509804 , -0.827451  ],\n         [-0.77254903, -0.88235295, -0.8745098 ],\n         [-0.7882353 , -0.90588236, -0.8901961 ]],\n\n        [[-0.73333335, -0.8117647 , -0.75686276],\n         [-0.7411765 , -0.81960785, -0.75686276],\n         [-0.7411765 , -0.81960785, -0.75686276],\n         ...,\n         [-0.7411765 , -0.85882354, -0.8352941 ],\n         [-0.78039217, -0.8901961 , -0.88235295],\n         [-0.7882353 , -0.90588236, -0.8980392 ]],\n\n        [[-0.75686276, -0.8509804 , -0.7882353 ],\n         [-0.7411765 , -0.8352941 , -0.7647059 ],\n         [-0.7254902 , -0.81960785, -0.7490196 ],\n         ...,\n         [-0.75686276, -0.8745098 , -0.84313726],\n         [-0.79607844, -0.90588236, -0.8980392 ],\n         [-0.7882353 , -0.90588236, -0.8901961 ]],\n\n        ...,\n\n        [[-0.5529412 , -0.52156866, -0.42745095],\n         [-0.52156866, -0.49019605, -0.3960784 ],\n         [-0.5294118 , -0.4980392 , -0.40392154],\n         ...,\n         [-0.32549018, -0.31764704, -0.20784312],\n         [-0.45098037, -0.4352941 , -0.3333333 ],\n         [-0.3098039 , -0.29411763, -0.18431371]],\n\n        [[-0.5686275 , -0.5372549 , -0.44313723],\n         [-0.56078434, -0.5294118 , -0.4352941 ],\n         [-0.5921569 , -0.56078434, -0.46666664],\n         ...,\n         [-0.3490196 , -0.3333333 , -0.23137254],\n         [-0.3490196 , -0.3333333 , -0.23137254],\n         [-0.42745095, -0.41176468, -0.30196077]],\n\n        [[-0.6       , -0.5686275 , -0.47450978],\n         [-0.6       , -0.5686275 , -0.47450978],\n         [-0.6       , -0.5686275 , -0.47450978],\n         ...,\n         [-0.41960782, -0.40392154, -0.30196077],\n         [-0.372549  , -0.35686272, -0.25490195],\n         [-0.372549  , -0.35686272, -0.23921567]]],\n\n\n       [[[-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         ...,\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ]],\n\n        [[-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         ...,\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ]],\n\n        [[-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         ...,\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ]],\n\n        ...,\n\n        [[-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         ...,\n         [-0.9137255 , -0.90588236, -0.8745098 ],\n         [-0.94509804, -0.9372549 , -0.9137255 ],\n         [-0.94509804, -0.94509804, -0.92156863]],\n\n        [[-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         ...,\n         [-0.94509804, -0.9372549 , -0.90588236],\n         [-0.9529412 , -0.94509804, -0.9137255 ],\n         [-0.9372549 , -0.92941177, -0.9137255 ]],\n\n        [[-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         [-0.99215686, -0.99215686, -0.99215686],\n         ...,\n         [-0.92941177, -0.92156863, -0.8901961 ],\n         [-0.94509804, -0.9372549 , -0.90588236],\n         [-0.94509804, -0.94509804, -0.92156863]]],\n\n\n       [[[ 0.7176471 ,  0.7490196 ,  0.84313726],\n         [ 0.70980394,  0.7411765 ,  0.8352941 ],\n         [ 0.7019608 ,  0.73333335,  0.827451  ],\n         ...,\n         [ 0.5764706 ,  0.52156866,  0.5764706 ],\n         [ 0.6862745 ,  0.60784316,  0.67058825],\n         [ 0.6313726 ,  0.6       ,  0.64705884]],\n\n        [[ 0.7411765 ,  0.77254903,  0.8666667 ],\n         [ 0.7254902 ,  0.75686276,  0.8509804 ],\n         [ 0.7254902 ,  0.75686276,  0.8509804 ],\n         ...,\n         [ 0.60784316,  0.5529412 ,  0.60784316],\n         [ 0.67058825,  0.6       ,  0.6627451 ],\n         [ 0.60784316,  0.5686275 ,  0.6156863 ]],\n\n        [[ 0.75686276,  0.7882353 ,  0.88235295],\n         [ 0.75686276,  0.7882353 ,  0.88235295],\n         [ 0.7647059 ,  0.79607844,  0.8901961 ],\n         ...,\n         [ 0.6313726 ,  0.5764706 ,  0.6313726 ],\n         [ 0.67058825,  0.5921569 ,  0.654902  ],\n         [ 0.5921569 ,  0.56078434,  0.60784316]],\n\n        ...,\n\n        [[-0.9529412 , -0.9529412 , -0.9372549 ],\n         [-0.94509804, -0.94509804, -0.92941177],\n         [-0.9372549 , -0.9372549 , -0.92156863],\n         ...,\n         [-0.69411767, -0.6862745 , -0.64705884],\n         [-0.69411767, -0.6862745 , -0.64705884],\n         [-0.70980394, -0.7019608 , -0.6627451 ]],\n\n        [[-0.92941177, -0.92941177, -0.9137255 ],\n         [-0.92156863, -0.92156863, -0.90588236],\n         [-0.92156863, -0.92156863, -0.90588236],\n         ...,\n         [-0.6627451 , -0.654902  , -0.6156863 ],\n         [-0.6862745 , -0.6784314 , -0.6392157 ],\n         [-0.70980394, -0.7019608 , -0.6627451 ]],\n\n        [[-0.9137255 , -0.9137255 , -0.8980392 ],\n         [-0.8980392 , -0.8980392 , -0.88235295],\n         [-0.9137255 , -0.9137255 , -0.8980392 ],\n         ...,\n         [-0.6784314 , -0.67058825, -0.6313726 ],\n         [-0.70980394, -0.7019608 , -0.6627451 ],\n         [-0.7411765 , -0.73333335, -0.69411767]]],\n\n\n       ...,\n\n\n       [[[ 0.99215686,  0.9764706 ,  0.9843137 ],\n         [ 0.99215686,  0.9764706 ,  0.9843137 ],\n         [ 0.99215686,  0.9764706 ,  0.9843137 ],\n         ...,\n         [ 1.        ,  0.99215686,  0.9764706 ],\n         [ 1.        ,  0.99215686,  0.9764706 ],\n         [ 1.        ,  1.        ,  0.9843137 ]],\n\n        [[ 0.99215686,  0.9843137 ,  0.9843137 ],\n         [ 0.99215686,  0.9843137 ,  0.9843137 ],\n         [ 0.99215686,  0.9843137 ,  0.9843137 ],\n         ...,\n         [ 1.        ,  0.99215686,  0.9764706 ],\n         [ 1.        ,  0.99215686,  0.9764706 ],\n         [ 1.        ,  1.        ,  0.9843137 ]],\n\n        [[ 0.96862745,  0.9607843 ,  0.9372549 ],\n         [ 0.96862745,  0.9607843 ,  0.9372549 ],\n         [ 0.96862745,  0.9607843 ,  0.9372549 ],\n         ...,\n         [ 1.        ,  0.99215686,  0.9764706 ],\n         [ 1.        ,  0.99215686,  0.9764706 ],\n         [ 1.        ,  1.        ,  0.9843137 ]],\n\n        ...,\n\n        [[ 0.67058825,  0.6       ,  0.62352943],\n         [ 0.7411765 ,  0.6862745 ,  0.7019608 ],\n         [ 0.70980394,  0.6784314 ,  0.6862745 ],\n         ...,\n         [-0.16862744, -0.1372549 , -0.09803921],\n         [-0.19999999, -0.12941176, -0.09019607],\n         [ 0.17647064,  0.21568632,  0.2313726 ]],\n\n        [[ 0.5686275 ,  0.49803925,  0.52156866],\n         [ 0.6784314 ,  0.6313726 ,  0.64705884],\n         [ 0.6784314 ,  0.6392157 ,  0.64705884],\n         ...,\n         [-0.17647058, -0.19215685, -0.14509803],\n         [-0.17647058, -0.16862744, -0.11372548],\n         [ 0.20000005,  0.20784318,  0.2313726 ]],\n\n        [[ 0.5764706 ,  0.5137255 ,  0.5372549 ],\n         [ 0.7254902 ,  0.6784314 ,  0.69411767],\n         [ 0.7647059 ,  0.7254902 ,  0.73333335],\n         ...,\n         [-0.29411763, -0.372549  , -0.3098039 ],\n         [-0.19999999, -0.24705881, -0.19215685],\n         [ 0.16078436,  0.14509809,  0.17647064]]],\n\n\n       [[[-0.5294118 , -0.27843136, -0.36470586],\n         [-0.5058824 , -0.26274508, -0.34117645],\n         [-0.5529412 , -0.31764704, -0.38823527],\n         ...,\n         [-0.8666667 , -0.84313726, -0.7882353 ],\n         [-0.85882354, -0.827451  , -0.8039216 ],\n         [-0.92941177, -0.8745098 , -0.8666667 ]],\n\n        [[-0.52156866, -0.27058822, -0.35686272],\n         [-0.5137255 , -0.26274508, -0.3490196 ],\n         [-0.56078434, -0.32549018, -0.38823527],\n         ...,\n         [-0.8666667 , -0.84313726, -0.7882353 ],\n         [-0.85882354, -0.827451  , -0.8039216 ],\n         [-0.92941177, -0.8745098 , -0.8666667 ]],\n\n        [[-0.52156866, -0.27058822, -0.35686272],\n         [-0.5137255 , -0.26274508, -0.3490196 ],\n         [-0.56078434, -0.32549018, -0.38823527],\n         ...,\n         [-0.85882354, -0.8352941 , -0.78039217],\n         [-0.8666667 , -0.8352941 , -0.8117647 ],\n         [-0.9372549 , -0.88235295, -0.8666667 ]],\n\n        ...,\n\n        [[-0.46666664, -0.17647058, -0.24705881],\n         [-0.5686275 , -0.34117645, -0.40392154],\n         [-0.5764706 , -0.42745095, -0.46666664],\n         ...,\n         [ 0.4666667 ,  0.28627455,  0.3176471 ],\n         [ 0.48235297,  0.2941177 ,  0.3176471 ],\n         [ 0.36470592,  0.1686275 ,  0.19215691]],\n\n        [[-0.4588235 , -0.17647058, -0.23921567],\n         [-0.6156863 , -0.3960784 , -0.45098037],\n         [-0.60784316, -0.45098037, -0.4980392 ],\n         ...,\n         [ 0.5137255 ,  0.34901965,  0.36470592],\n         [ 0.49803925,  0.30196083,  0.32549024],\n         [ 0.45098042,  0.254902  ,  0.27058828]],\n\n        [[-0.46666664, -0.18431371, -0.24705881],\n         [-0.6313726 , -0.41176468, -0.47450978],\n         [-0.58431375, -0.4352941 , -0.4823529 ],\n         ...,\n         [ 0.52156866,  0.37254906,  0.3803922 ],\n         [ 0.47450984,  0.30980396,  0.30196083],\n         [ 0.43529415,  0.26274514,  0.24705887]]],\n\n\n       [[[ 0.14509809,  0.3803922 ,  0.45882356],\n         [ 0.15294123,  0.38823533,  0.4666667 ],\n         [ 0.14509809,  0.3803922 ,  0.45882356],\n         ...,\n         [-0.4588235 , -0.3333333 , -0.4352941 ],\n         [-0.45098037, -0.32549018, -0.42745095],\n         [-0.41960782, -0.29411763, -0.3960784 ]],\n\n        [[ 0.14509809,  0.3803922 ,  0.45882356],\n         [ 0.15294123,  0.38823533,  0.4666667 ],\n         [ 0.14509809,  0.3803922 ,  0.45882356],\n         ...,\n         [-0.4588235 , -0.3333333 , -0.4352941 ],\n         [-0.45098037, -0.32549018, -0.42745095],\n         [-0.41960782, -0.29411763, -0.3960784 ]],\n\n        [[ 0.14509809,  0.3803922 ,  0.45882356],\n         [ 0.15294123,  0.38823533,  0.4666667 ],\n         [ 0.14509809,  0.3803922 ,  0.45882356],\n         ...,\n         [-0.46666664, -0.34117645, -0.44313723],\n         [-0.44313723, -0.31764704, -0.41960782],\n         [-0.42745095, -0.30196077, -0.40392154]],\n\n        ...,\n\n        [[-0.6       , -0.6       , -0.6156863 ],\n         [-0.78039217, -0.78039217, -0.79607844],\n         [-0.85882354, -0.85882354, -0.8745098 ],\n         ...,\n         [ 0.79607844,  0.7254902 ,  0.6627451 ],\n         [ 0.8117647 ,  0.7411765 ,  0.6784314 ],\n         [ 0.8117647 ,  0.7647059 ,  0.7176471 ]],\n\n        [[-0.6784314 , -0.6784314 , -0.69411767],\n         [-0.8039216 , -0.8039216 , -0.81960785],\n         [-0.8745098 , -0.8745098 , -0.8901961 ],\n         ...,\n         [ 0.7411765 ,  0.67058825,  0.6       ],\n         [ 0.75686276,  0.6862745 ,  0.60784316],\n         [ 0.77254903,  0.7254902 ,  0.67058825]],\n\n        [[-0.7882353 , -0.7882353 , -0.8039216 ],\n         [-0.8745098 , -0.8745098 , -0.8901961 ],\n         [-0.8980392 , -0.8980392 , -0.9137255 ],\n         ...,\n         [ 0.7019608 ,  0.6313726 ,  0.5686275 ],\n         [ 0.70980394,  0.6313726 ,  0.56078434],\n         [ 0.7176471 ,  0.6627451 ,  0.6156863 ]]]], dtype=float32)>,\n  4: <tf.Tensor: shape=(64, 64, 64, 3), dtype=float32, numpy=\narray([[[[ 0.5372549 ,  0.52156866,  0.60784316],\n         [ 0.5372549 ,  0.52156866,  0.60784316],\n         [ 0.5372549 ,  0.52156866,  0.60784316],\n         ...,\n         [ 0.54509807,  0.54509807,  0.6392157 ],\n         [ 0.54509807,  0.54509807,  0.6392157 ],\n         [ 0.54509807,  0.54509807,  0.6392157 ]],\n\n        [[ 0.54509807,  0.5294118 ,  0.6156863 ],\n         [ 0.54509807,  0.5294118 ,  0.6156863 ],\n         [ 0.54509807,  0.5294118 ,  0.6156863 ],\n         ...,\n         [ 0.54509807,  0.54509807,  0.6392157 ],\n         [ 0.54509807,  0.54509807,  0.6392157 ],\n         [ 0.54509807,  0.54509807,  0.6392157 ]],\n\n        [[ 0.5529412 ,  0.5372549 ,  0.62352943],\n         [ 0.5529412 ,  0.5372549 ,  0.62352943],\n         [ 0.5529412 ,  0.5372549 ,  0.62352943],\n         ...,\n         [ 0.54509807,  0.54509807,  0.6392157 ],\n         [ 0.54509807,  0.54509807,  0.6392157 ],\n         [ 0.54509807,  0.54509807,  0.6392157 ]],\n\n        ...,\n\n        [[-0.77254903, -0.77254903, -0.77254903],\n         [-0.7411765 , -0.7411765 , -0.7411765 ],\n         [-0.75686276, -0.75686276, -0.75686276],\n         ...,\n         [ 0.69411767,  0.7254902 ,  0.7882353 ],\n         [ 0.5921569 ,  0.6313726 ,  0.7019608 ],\n         [ 0.6156863 ,  0.6313726 ,  0.70980394]],\n\n        [[-0.7490196 , -0.7490196 , -0.7490196 ],\n         [-0.7490196 , -0.7490196 , -0.7490196 ],\n         [-0.78039217, -0.78039217, -0.78039217],\n         ...,\n         [ 0.36470592,  0.3803922 ,  0.4431373 ],\n         [ 0.7019608 ,  0.7254902 ,  0.79607844],\n         [ 0.6392157 ,  0.64705884,  0.7176471 ]],\n\n        [[-0.7411765 , -0.7411765 , -0.7411765 ],\n         [-0.75686276, -0.75686276, -0.75686276],\n         [-0.7882353 , -0.7882353 , -0.7882353 ],\n         ...,\n         [-0.7019608 , -0.70980394, -0.6392157 ],\n         [ 0.06666672,  0.07450986,  0.16078436],\n         [ 0.654902  ,  0.654902  ,  0.73333335]]],\n\n\n       [[[-0.6       , -0.70980394, -0.6313726 ],\n         [-0.6392157 , -0.7019608 , -0.60784316],\n         [-0.6392157 , -0.6862745 , -0.6       ],\n         ...,\n         [-0.34117645, -0.60784316, -0.70980394],\n         [-0.32549018, -0.5921569 , -0.6784314 ],\n         [-0.31764704, -0.6       , -0.7019608 ]],\n\n        [[-0.6       , -0.70980394, -0.6313726 ],\n         [-0.6313726 , -0.7019608 , -0.60784316],\n         [-0.64705884, -0.69411767, -0.60784316],\n         ...,\n         [-0.3333333 , -0.6       , -0.7019608 ],\n         [-0.3333333 , -0.6       , -0.69411767],\n         [-0.32549018, -0.6       , -0.70980394]],\n\n        [[-0.6       , -0.70980394, -0.6313726 ],\n         [-0.6313726 , -0.7019608 , -0.60784316],\n         [-0.64705884, -0.69411767, -0.60784316],\n         ...,\n         [-0.34117645, -0.60784316, -0.70980394],\n         [-0.3333333 , -0.6       , -0.69411767],\n         [-0.31764704, -0.6       , -0.7019608 ]],\n\n        ...,\n\n        [[ 0.27058828,  0.20784318,  0.34901965],\n         [ 0.27058828,  0.20000005,  0.34901965],\n         [ 0.28627455,  0.22352946,  0.36470592],\n         ...,\n         [ 0.14509809,  0.14509809,  0.18431377],\n         [ 0.20000005,  0.1686275 ,  0.21568632],\n         [-0.02745098, -0.1372549 , -0.15294117]],\n\n        [[ 0.20784318,  0.15294123,  0.2941177 ],\n         [ 0.18431377,  0.12156868,  0.27058828],\n         [ 0.1686275 ,  0.11372554,  0.254902  ],\n         ...,\n         [ 0.09803927,  0.09803927,  0.13725495],\n         [ 0.20000005,  0.17647064,  0.22352946],\n         [-0.04313725, -0.11372548, -0.12156862]],\n\n        [[-0.12941176, -0.1607843 , -0.02745098],\n         [-0.12941176, -0.1607843 , -0.02745098],\n         [-0.12156862, -0.15294117, -0.01960784],\n         ...,\n         [ 0.02745104,  0.03529418,  0.06666672],\n         [ 0.21568632,  0.19215691,  0.23921573],\n         [-0.0745098 , -0.10588235, -0.12156862]]],\n\n\n       [[[ 1.        ,  0.90588236,  0.99215686],\n         [ 0.9843137 ,  0.8980392 ,  0.9764706 ],\n         [ 1.        ,  0.9529412 ,  1.        ],\n         ...,\n         [ 0.96862745,  1.        ,  1.        ],\n         [ 0.9529412 ,  0.9843137 ,  0.99215686],\n         [ 0.9529412 ,  0.9764706 ,  1.        ]],\n\n        [[ 0.9843137 ,  0.90588236,  0.99215686],\n         [ 0.96862745,  0.90588236,  0.96862745],\n         [ 0.9764706 ,  0.96862745,  1.        ],\n         ...,\n         [ 0.96862745,  1.        ,  1.        ],\n         [ 0.9529412 ,  0.9843137 ,  0.99215686],\n         [ 0.9529412 ,  0.9764706 ,  1.        ]],\n\n        [[ 0.9764706 ,  0.90588236,  0.9843137 ],\n         [ 0.9843137 ,  0.9372549 ,  0.99215686],\n         [ 0.9843137 ,  0.99215686,  1.        ],\n         ...,\n         [ 0.9607843 ,  0.99215686,  1.        ],\n         [ 0.9529412 ,  0.9843137 ,  0.99215686],\n         [ 0.9607843 ,  0.99215686,  1.        ]],\n\n        ...,\n\n        [[ 0.8352941 ,  0.54509807,  0.30980396],\n         [ 0.8352941 ,  0.5137255 ,  0.27058828],\n         [ 0.7882353 ,  0.43529415,  0.17647064],\n         ...,\n         [ 0.90588236,  0.70980394,  0.5529412 ],\n         [ 0.88235295,  0.69411767,  0.5372549 ],\n         [ 0.94509804,  0.654902  ,  0.6627451 ]],\n\n        [[ 0.75686276,  0.4666667 ,  0.21568632],\n         [ 0.7647059 ,  0.45098042,  0.20000005],\n         [ 0.7490196 ,  0.41176474,  0.16078436],\n         ...,\n         [ 0.85882354,  0.6313726 ,  0.47450984],\n         [ 0.85882354,  0.6392157 ,  0.47450984],\n         [ 0.92156863,  0.64705884,  0.6784314 ]],\n\n        [[ 0.79607844,  0.5058824 ,  0.26274514],\n         [ 0.78039217,  0.4666667 ,  0.21568632],\n         [ 0.7411765 ,  0.39607847,  0.14509809],\n         ...,\n         [ 0.88235295,  0.64705884,  0.47450984],\n         [ 0.8980392 ,  0.654902  ,  0.48235297],\n         [ 0.8901961 ,  0.654902  ,  0.70980394]]],\n\n\n       ...,\n\n\n       [[[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [-0.5137255 , -0.54509807, -0.5529412 ],\n         [-0.5137255 , -0.54509807, -0.5529412 ],\n         [-0.5137255 , -0.54509807, -0.5529412 ]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [-0.4980392 , -0.5294118 , -0.5372549 ],\n         [-0.4980392 , -0.5294118 , -0.5372549 ],\n         [-0.5058824 , -0.5372549 , -0.54509807]],\n\n        [[ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         [ 1.        ,  1.        ,  1.        ],\n         ...,\n         [-0.4980392 , -0.5294118 , -0.5372549 ],\n         [-0.4980392 , -0.5294118 , -0.5372549 ],\n         [-0.49019605, -0.52156866, -0.5294118 ]],\n\n        ...,\n\n        [[-0.77254903, -0.7647059 , -0.7647059 ],\n         [-0.77254903, -0.7647059 , -0.7647059 ],\n         [-0.7647059 , -0.7647059 , -0.7647059 ],\n         ...,\n         [ 0.47450984, -0.02745098, -0.14509803],\n         [ 0.5058824 ,  0.02745104, -0.08235294],\n         [ 0.5921569 ,  0.06666672, -0.03529412]],\n\n        [[-0.7490196 , -0.7490196 , -0.7490196 ],\n         [-0.7490196 , -0.7490196 , -0.7490196 ],\n         [-0.73333335, -0.73333335, -0.73333335],\n         ...,\n         [ 0.54509807,  0.00392163, -0.1607843 ],\n         [ 0.60784316,  0.05882359, -0.11372548],\n         [ 0.62352943,  0.082353  , -0.09019607]],\n\n        [[-0.7647059 , -0.7647059 , -0.7647059 ],\n         [-0.75686276, -0.75686276, -0.75686276],\n         [-0.7490196 , -0.7490196 , -0.7490196 ],\n         ...,\n         [ 0.6392157 ,  0.07450986, -0.1607843 ],\n         [ 0.69411767,  0.082353  , -0.12941176],\n         [ 0.7411765 ,  0.19215691, -0.04313725]]],\n\n\n       [[[-0.38039213, -0.10588235, -0.56078434],\n         [-0.38039213, -0.10588235, -0.56078434],\n         [-0.38039213, -0.10588235, -0.56078434],\n         ...,\n         [-0.25490195, -0.01960784, -0.5058824 ],\n         [-0.2235294 ,  0.00392163, -0.4588235 ],\n         [-0.2235294 , -0.00392157, -0.49019605]],\n\n        [[-0.38039213, -0.09803921, -0.5764706 ],\n         [-0.38039213, -0.09803921, -0.5764706 ],\n         [-0.38039213, -0.09803921, -0.5764706 ],\n         ...,\n         [-0.36470586, -0.12941176, -0.60784316],\n         [-0.31764704, -0.09019607, -0.5294118 ],\n         [-0.25490195, -0.01960784, -0.47450978]],\n\n        [[-0.38823527, -0.10588235, -0.5921569 ],\n         [-0.38823527, -0.10588235, -0.5921569 ],\n         [-0.38823527, -0.10588235, -0.5921569 ],\n         ...,\n         [-0.3960784 , -0.15294117, -0.6       ],\n         [-0.36470586, -0.12941176, -0.5294118 ],\n         [-0.27843136, -0.02745098, -0.41960782]],\n\n        ...,\n\n        [[-0.09019607, -0.03529412, -0.7254902 ],\n         [-0.11372548, -0.03529412, -0.6627451 ],\n         [-0.10588235, -0.03529412, -0.6862745 ],\n         ...,\n         [-0.75686276, -0.42745095, -0.19999999],\n         [-0.96862745, -0.62352943, -0.372549  ],\n         [-0.92156863, -0.58431375, -0.34117645]],\n\n        [[ 0.15294123,  0.20784318, -0.56078434],\n         [ 0.12156868,  0.20784318, -0.47450978],\n         [ 0.09803927,  0.21568632, -0.4823529 ],\n         ...,\n         [-0.7882353 , -0.41176468, -0.1372549 ],\n         [-0.6392157 , -0.24705881,  0.03529418],\n         [-0.58431375, -0.20784312,  0.07450986]],\n\n        [[ 0.09019613,  0.1686275 , -0.6784314 ],\n         [ 0.05882359,  0.1686275 , -0.6       ],\n         [ 0.03529418,  0.18431377, -0.5921569 ],\n         ...,\n         [-0.6627451 , -0.25490195,  0.05882359],\n         [-0.78039217, -0.372549  , -0.04313725],\n         [-0.8352941 , -0.42745095, -0.10588235]]],\n\n\n       [[[ 0.6627451 ,  0.70980394,  0.69411767],\n         [ 0.67058825,  0.7176471 ,  0.7019608 ],\n         [ 0.6784314 ,  0.7254902 ,  0.70980394],\n         ...,\n         [ 0.7490196 ,  0.8117647 ,  0.827451  ],\n         [ 0.7490196 ,  0.8117647 ,  0.827451  ],\n         [ 0.7411765 ,  0.8039216 ,  0.827451  ]],\n\n        [[ 0.6627451 ,  0.70980394,  0.69411767],\n         [ 0.67058825,  0.7176471 ,  0.7019608 ],\n         [ 0.6784314 ,  0.7254902 ,  0.70980394],\n         ...,\n         [ 0.7490196 ,  0.8117647 ,  0.827451  ],\n         [ 0.7490196 ,  0.8117647 ,  0.827451  ],\n         [ 0.7411765 ,  0.8039216 ,  0.827451  ]],\n\n        [[ 0.6627451 ,  0.70980394,  0.69411767],\n         [ 0.67058825,  0.7176471 ,  0.7019608 ],\n         [ 0.6784314 ,  0.7254902 ,  0.70980394],\n         ...,\n         [ 0.7490196 ,  0.8117647 ,  0.827451  ],\n         [ 0.7490196 ,  0.8117647 ,  0.827451  ],\n         [ 0.7490196 ,  0.8117647 ,  0.8352941 ]],\n\n        ...,\n\n        [[-0.8745098 , -0.8745098 , -0.8901961 ],\n         [-0.8352941 , -0.8352941 , -0.8509804 ],\n         [-0.84313726, -0.84313726, -0.85882354],\n         ...,\n         [-0.9137255 , -0.92156863, -0.94509804],\n         [-0.84313726, -0.8509804 , -0.8745098 ],\n         [-0.7882353 , -0.79607844, -0.81960785]],\n\n        [[-0.9372549 , -0.9372549 , -0.9529412 ],\n         [-0.8666667 , -0.8666667 , -0.88235295],\n         [-0.8352941 , -0.8352941 , -0.8509804 ],\n         ...,\n         [-0.8980392 , -0.90588236, -0.9372549 ],\n         [-0.81960785, -0.827451  , -0.85882354],\n         [-0.8980392 , -0.90588236, -0.92156863]],\n\n        [[-0.94509804, -0.94509804, -0.9607843 ],\n         [-0.92156863, -0.92156863, -0.9372549 ],\n         [-0.827451  , -0.827451  , -0.84313726],\n         ...,\n         [-0.8352941 , -0.84313726, -0.8745098 ],\n         [-0.84313726, -0.8509804 , -0.8901961 ],\n         [-0.94509804, -0.9529412 , -0.9764706 ]]]], dtype=float32)>,\n  5: <tf.Tensor: shape=(64, 64, 64, 3), dtype=float32, numpy=\narray([[[[-0.38039213, -0.5529412 , -0.6392157 ],\n         [-0.38039213, -0.5529412 , -0.6392157 ],\n         [-0.38039213, -0.5529412 , -0.6392157 ],\n         ...,\n         [ 0.654902  ,  0.5294118 ,  0.3803922 ],\n         [ 0.654902  ,  0.5137255 ,  0.35686278],\n         [ 0.6627451 ,  0.5058824 ,  0.36470592]],\n\n        [[-0.38823527, -0.56078434, -0.64705884],\n         [-0.38823527, -0.56078434, -0.64705884],\n         [-0.38823527, -0.56078434, -0.64705884],\n         ...,\n         [ 0.654902  ,  0.5294118 ,  0.3803922 ],\n         [ 0.654902  ,  0.5137255 ,  0.36470592],\n         [ 0.6627451 ,  0.5058824 ,  0.36470592]],\n\n        [[-0.38823527, -0.56078434, -0.64705884],\n         [-0.38823527, -0.56078434, -0.64705884],\n         [-0.38823527, -0.56078434, -0.64705884],\n         ...,\n         [ 0.64705884,  0.52156866,  0.37254906],\n         [ 0.64705884,  0.5058824 ,  0.35686278],\n         [ 0.654902  ,  0.49803925,  0.35686278]],\n\n        ...,\n\n        [[-0.46666664, -0.4352941 , -0.5058824 ],\n         [-0.38823527, -0.372549  , -0.42745095],\n         [-0.31764704, -0.3098039 , -0.3490196 ],\n         ...,\n         [-0.36470586, -0.372549  , -0.3960784 ],\n         [-0.372549  , -0.38039213, -0.41176468],\n         [-0.3490196 , -0.3490196 , -0.38039213]],\n\n        [[-0.40392154, -0.36470586, -0.4352941 ],\n         [-0.3098039 , -0.2862745 , -0.34117645],\n         [-0.30196077, -0.2862745 , -0.3333333 ],\n         ...,\n         [-0.35686272, -0.36470586, -0.3960784 ],\n         [-0.38823527, -0.3960784 , -0.42745095],\n         [-0.3333333 , -0.34117645, -0.372549  ]],\n\n        [[-0.38039213, -0.34117645, -0.41176468],\n         [-0.34117645, -0.31764704, -0.372549  ],\n         [-0.34117645, -0.3333333 , -0.38039213],\n         ...,\n         [-0.34117645, -0.3490196 , -0.38039213],\n         [-0.38039213, -0.38823527, -0.41960782],\n         [-0.38823527, -0.3960784 , -0.42745095]]],\n\n\n       [[[ 0.04313731, -0.06666666,  0.09019613],\n         [-0.05098039, -0.14509803,  0.00392163],\n         [-0.23137254, -0.29411763, -0.15294117],\n         ...,\n         [-1.        , -0.9529412 , -0.9843137 ],\n         [-0.654902  , -0.78039217, -0.81960785],\n         [ 0.0196079 , -0.372549  , -0.6       ]],\n\n        [[ 0.06666672, -0.05098039,  0.11372554],\n         [-0.03529412, -0.12941176,  0.02745104],\n         [-0.21568626, -0.27058822, -0.12941176],\n         ...,\n         [-1.        , -0.9529412 , -0.9764706 ],\n         [-0.7176471 , -0.827451  , -0.8745098 ],\n         [-0.05098039, -0.40392154, -0.62352943]],\n\n        [[ 0.06666672, -0.05098039,  0.11372554],\n         [-0.01960784, -0.11372548,  0.04313731],\n         [-0.19999999, -0.25490195, -0.11372548],\n         ...,\n         [-0.99215686, -0.96862745, -0.9843137 ],\n         [-0.77254903, -0.8745098 , -0.92941177],\n         [-0.12156862, -0.45098037, -0.654902  ]],\n\n        ...,\n\n        [[-0.9764706 , -0.9529412 , -0.8666667 ],\n         [-0.96862745, -0.9529412 , -0.8666667 ],\n         [-1.        , -0.9843137 , -0.8901961 ],\n         ...,\n         [ 0.8745098 ,  0.8980392 ,  1.        ],\n         [ 0.79607844,  0.827451  ,  0.96862745],\n         [ 0.78039217,  0.81960785,  0.8980392 ]],\n\n        [[-0.5686275 , -0.54509807, -0.45098037],\n         [-0.4980392 , -0.4823529 , -0.38039213],\n         [-0.18431371, -0.16862744, -0.05098039],\n         ...,\n         [ 0.7019608 ,  0.73333335,  0.8745098 ],\n         [ 0.7490196 ,  0.78039217,  0.9372549 ],\n         [ 0.78039217,  0.8117647 ,  0.94509804]],\n\n        [[ 0.69411767,  0.6862745 ,  0.8039216 ],\n         [ 0.7176471 ,  0.70980394,  0.8352941 ],\n         [ 0.79607844,  0.7882353 ,  0.92156863],\n         ...,\n         [ 0.7411765 ,  0.7411765 ,  0.8980392 ],\n         [ 0.7647059 ,  0.77254903,  0.92941177],\n         [ 0.77254903,  0.78039217,  0.9529412 ]]],\n\n\n       [[[ 1.        ,  0.9372549 ,  0.6627451 ],\n         [ 0.99215686,  0.92941177,  0.69411767],\n         [ 1.        ,  0.92156863,  0.7411765 ],\n         ...,\n         [ 0.9372549 ,  0.8745098 ,  0.77254903],\n         [ 0.9372549 ,  0.8745098 ,  0.77254903],\n         [ 0.9372549 ,  0.8745098 ,  0.77254903]],\n\n        [[ 1.        ,  0.9372549 ,  0.6627451 ],\n         [ 0.99215686,  0.92941177,  0.69411767],\n         [ 1.        ,  0.92156863,  0.7411765 ],\n         ...,\n         [ 0.9372549 ,  0.8745098 ,  0.77254903],\n         [ 0.9372549 ,  0.8745098 ,  0.77254903],\n         [ 0.9372549 ,  0.8745098 ,  0.77254903]],\n\n        [[ 1.        ,  0.9372549 ,  0.654902  ],\n         [ 0.99215686,  0.92156863,  0.6862745 ],\n         [ 1.        ,  0.92941177,  0.7490196 ],\n         ...,\n         [ 0.9372549 ,  0.8745098 ,  0.77254903],\n         [ 0.9372549 ,  0.8745098 ,  0.77254903],\n         [ 0.9372549 ,  0.8745098 ,  0.77254903]],\n\n        ...,\n\n        [[-0.8901961 , -0.8980392 , -0.9843137 ],\n         [-0.9137255 , -0.9137255 , -1.        ],\n         [-0.90588236, -0.8901961 , -0.96862745],\n         ...,\n         [ 0.26274514, -0.11372548, -0.40392154],\n         [ 0.24705887, -0.12156862, -0.41960782],\n         [ 0.2313726 , -0.1372549 , -0.4352941 ]],\n\n        [[-0.85882354, -0.8745098 , -0.96862745],\n         [-0.92156863, -0.92156863, -1.        ],\n         [-0.9137255 , -0.90588236, -0.9843137 ],\n         ...,\n         [ 0.73333335,  0.35686278, -0.09019607],\n         [ 0.7254902 ,  0.34901965, -0.09019607],\n         [ 0.73333335,  0.34901965, -0.09019607]],\n\n        [[-0.81960785, -0.827451  , -0.92156863],\n         [-0.90588236, -0.90588236, -0.9843137 ],\n         [-0.92941177, -0.9137255 , -1.        ],\n         ...,\n         [ 0.54509807,  0.14509809, -0.24705881],\n         [ 0.54509807,  0.14509809, -0.23921567],\n         [ 0.5529412 ,  0.15294123, -0.23137254]]],\n\n\n       ...,\n\n\n       [[[ 0.48235297,  0.4901961 ,  0.5058824 ],\n         [ 0.48235297,  0.4901961 ,  0.5058824 ],\n         [ 0.48235297,  0.4901961 ,  0.5058824 ],\n         ...,\n         [ 0.45882356,  0.4666667 ,  0.48235297],\n         [ 0.45882356,  0.4666667 ,  0.48235297],\n         [ 0.45882356,  0.4666667 ,  0.48235297]],\n\n        [[ 0.48235297,  0.4901961 ,  0.5058824 ],\n         [ 0.48235297,  0.4901961 ,  0.5058824 ],\n         [ 0.48235297,  0.4901961 ,  0.5058824 ],\n         ...,\n         [ 0.45882356,  0.4666667 ,  0.48235297],\n         [ 0.45882356,  0.4666667 ,  0.48235297],\n         [ 0.45882356,  0.4666667 ,  0.48235297]],\n\n        [[ 0.48235297,  0.4901961 ,  0.5058824 ],\n         [ 0.48235297,  0.4901961 ,  0.5058824 ],\n         [ 0.48235297,  0.4901961 ,  0.5058824 ],\n         ...,\n         [ 0.45882356,  0.4666667 ,  0.48235297],\n         [ 0.45882356,  0.4666667 ,  0.48235297],\n         [ 0.45882356,  0.4666667 ,  0.48235297]],\n\n        ...,\n\n        [[ 0.12941182, -0.04313725, -0.5058824 ],\n         [ 0.23921573,  0.06666672, -0.3960784 ],\n         [ 0.05882359, -0.09803921, -0.56078434],\n         ...,\n         [ 0.9137255 , -0.14509803,  0.12941182],\n         [ 0.92156863, -0.14509803,  0.12156868],\n         [ 0.9137255 , -0.14509803,  0.14509809]],\n\n        [[ 0.28627455,  0.09803927, -0.25490195],\n         [ 0.254902  ,  0.05882359, -0.27843136],\n         [ 0.24705887,  0.06666672, -0.27058822],\n         ...,\n         [ 0.94509804, -0.11372548,  0.13725495],\n         [ 0.94509804, -0.11372548,  0.14509809],\n         [ 0.94509804, -0.09803921,  0.1686275 ]],\n\n        [[ 0.58431375,  0.4039216 , -0.01960784],\n         [ 0.37254906,  0.19215691, -0.21568626],\n         [ 0.26274514,  0.09803927, -0.2862745 ],\n         ...,\n         [ 0.94509804, -0.11372548,  0.14509809],\n         [ 0.9529412 , -0.10588235,  0.15294123],\n         [ 0.9607843 , -0.09019607,  0.17647064]]],\n\n\n       [[[-0.7490196 , -0.15294117,  0.6156863 ],\n         [-0.7490196 , -0.15294117,  0.6156863 ],\n         [-0.7490196 , -0.15294117,  0.6156863 ],\n         ...,\n         [-0.6784314 , -0.20784312,  0.5764706 ],\n         [-0.67058825, -0.15294117,  0.6862745 ],\n         [-0.69411767, -0.10588235,  0.67058825]],\n\n        [[-0.75686276, -0.1607843 ,  0.60784316],\n         [-0.75686276, -0.1607843 ,  0.60784316],\n         [-0.75686276, -0.1607843 ,  0.60784316],\n         ...,\n         [-0.6627451 , -0.17647058,  0.62352943],\n         [-0.6627451 , -0.12941176,  0.6862745 ],\n         [-0.7019608 , -0.09803921,  0.6627451 ]],\n\n        [[-0.73333335, -0.1372549 ,  0.6313726 ],\n         [-0.73333335, -0.1372549 ,  0.6313726 ],\n         [-0.73333335, -0.1372549 ,  0.6313726 ],\n         ...,\n         [-0.67058825, -0.15294117,  0.6627451 ],\n         [-0.6784314 , -0.09803921,  0.6784314 ],\n         [-0.70980394, -0.09803921,  0.64705884]],\n\n        ...,\n\n        [[-0.7647059 , -0.4588235 ,  0.14509809],\n         [-0.60784316, -0.3490196 ,  0.24705887],\n         [-0.5529412 , -0.3490196 ,  0.20000005],\n         ...,\n         [ 0.41960788, -0.25490195, -0.46666664],\n         [-0.08235294, -0.08235294, -0.45098037],\n         [-0.56078434,  0.05098045, -0.372549  ]],\n\n        [[-0.67058825, -0.38823527,  0.36470592],\n         [-0.54509807, -0.32549018,  0.41960788],\n         [-0.6313726 , -0.4823529 ,  0.23921573],\n         ...,\n         [ 0.60784316, -0.5137255 , -0.64705884],\n         [ 0.21568632, -0.23137254, -0.5137255 ],\n         [-0.3490196 , -0.12156862, -0.4352941 ]],\n\n        [[-0.5921569 , -0.29411763,  0.41960788],\n         [-0.58431375, -0.3490196 ,  0.34901965],\n         [-0.7647059 , -0.6       ,  0.09803927],\n         ...,\n         [ 0.85882354, -0.45098037, -0.5764706 ],\n         [ 0.39607847, -0.29411763, -0.5372549 ],\n         [-0.32549018, -0.27843136, -0.56078434]]],\n\n\n       [[[ 0.45098042,  0.64705884,  0.88235295],\n         [ 0.45098042,  0.64705884,  0.88235295],\n         [ 0.4431373 ,  0.6313726 ,  0.8666667 ],\n         ...,\n         [ 0.20784318,  0.48235297,  0.7882353 ],\n         [ 0.22352946,  0.49803925,  0.81960785],\n         [ 0.22352946,  0.49803925,  0.8117647 ]],\n\n        [[ 0.3803922 ,  0.6       ,  0.827451  ],\n         [ 0.39607847,  0.60784316,  0.84313726],\n         [ 0.4039216 ,  0.60784316,  0.84313726],\n         ...,\n         [ 0.20784318,  0.48235297,  0.7882353 ],\n         [ 0.22352946,  0.49803925,  0.81960785],\n         [ 0.22352946,  0.49803925,  0.8117647 ]],\n\n        [[ 0.3411765 ,  0.6       ,  0.827451  ],\n         [ 0.3803922 ,  0.6313726 ,  0.8666667 ],\n         [ 0.38823533,  0.62352943,  0.85882354],\n         ...,\n         [ 0.20784318,  0.48235297,  0.7882353 ],\n         [ 0.22352946,  0.49803925,  0.8117647 ],\n         [ 0.22352946,  0.49803925,  0.8117647 ]],\n\n        ...,\n\n        [[ 0.7019608 ,  0.8117647 ,  0.94509804],\n         [ 0.6862745 ,  0.8117647 ,  0.9372549 ],\n         [ 0.69411767,  0.827451  ,  0.9529412 ],\n         ...,\n         [ 0.73333335,  0.827451  ,  0.9607843 ],\n         [ 0.7176471 ,  0.81960785,  0.9529412 ],\n         [ 0.7254902 ,  0.827451  ,  0.9607843 ]],\n\n        [[ 0.70980394,  0.8117647 ,  0.94509804],\n         [ 0.69411767,  0.81960785,  0.94509804],\n         [ 0.69411767,  0.827451  ,  0.9529412 ],\n         ...,\n         [ 0.73333335,  0.827451  ,  0.9607843 ],\n         [ 0.7176471 ,  0.81960785,  0.9529412 ],\n         [ 0.7254902 ,  0.827451  ,  0.9607843 ]],\n\n        [[ 0.70980394,  0.8117647 ,  0.94509804],\n         [ 0.69411767,  0.81960785,  0.94509804],\n         [ 0.6862745 ,  0.81960785,  0.94509804],\n         ...,\n         [ 0.73333335,  0.827451  ,  0.96862745],\n         [ 0.7254902 ,  0.827451  ,  0.9607843 ],\n         [ 0.7254902 ,  0.827451  ,  0.9607843 ]]]], dtype=float32)>,\n  6: <tf.Tensor: shape=(64, 64, 64, 3), dtype=float32, numpy=\narray([[[[-0.9529412 , -0.9529412 , -0.9529412 ],\n         [-0.9529412 , -0.9529412 , -0.9529412 ],\n         [-0.96862745, -0.96862745, -0.96862745],\n         ...,\n         [-0.9529412 , -0.9529412 , -0.9529412 ],\n         [-0.9529412 , -0.9529412 , -0.9529412 ],\n         [-0.9529412 , -0.9529412 , -0.9529412 ]],\n\n        [[-0.9529412 , -0.9529412 , -0.9529412 ],\n         [-0.9529412 , -0.9529412 , -0.9529412 ],\n         [-0.96862745, -0.96862745, -0.96862745],\n         ...,\n         [-0.9529412 , -0.9529412 , -0.9529412 ],\n         [-0.9529412 , -0.9529412 , -0.9529412 ],\n         [-0.9529412 , -0.9529412 , -0.9529412 ]],\n\n        [[-0.9529412 , -0.9529412 , -0.9529412 ],\n         [-0.9529412 , -0.9529412 , -0.9529412 ],\n         [-0.96862745, -0.96862745, -0.96862745],\n         ...,\n         [-0.9529412 , -0.9529412 , -0.9529412 ],\n         [-0.9529412 , -0.9529412 , -0.9529412 ],\n         [-0.9529412 , -0.9529412 , -0.9529412 ]],\n\n        ...,\n\n        [[-0.7882353 , -0.8509804 , -0.8666667 ],\n         [-0.77254903, -0.81960785, -0.8352941 ],\n         [-0.81960785, -0.8509804 , -0.8745098 ],\n         ...,\n         [-0.16862744, -0.3490196 , -0.56078434],\n         [-0.18431371, -0.372549  , -0.5764706 ],\n         [-0.18431371, -0.372549  , -0.5764706 ]],\n\n        [[-0.7882353 , -0.8509804 , -0.8666667 ],\n         [-0.77254903, -0.81960785, -0.8352941 ],\n         [-0.81960785, -0.8509804 , -0.8745098 ],\n         ...,\n         [-0.12941176, -0.31764704, -0.52156866],\n         [-0.1372549 , -0.32549018, -0.5294118 ],\n         [-0.1372549 , -0.32549018, -0.5294118 ]],\n\n        [[-0.79607844, -0.85882354, -0.8745098 ],\n         [-0.78039217, -0.81960785, -0.84313726],\n         [-0.827451  , -0.85882354, -0.88235295],\n         ...,\n         [-0.09803921, -0.2862745 , -0.49019605],\n         [-0.10588235, -0.29411763, -0.4980392 ],\n         [-0.10588235, -0.29411763, -0.4980392 ]]],\n\n\n       [[[ 0.69411767,  0.07450986,  0.05098045],\n         [ 0.6784314 ,  0.07450986,  0.06666672],\n         [ 0.6627451 ,  0.082353  ,  0.07450986],\n         ...,\n         [ 0.64705884, -0.46666664, -0.654902  ],\n         [ 0.5058824 , -0.10588235, -0.20784312],\n         [ 0.90588236,  0.8352941 ,  0.78039217]],\n\n        [[ 0.69411767,  0.07450986,  0.05098045],\n         [ 0.6784314 ,  0.07450986,  0.06666672],\n         [ 0.6627451 ,  0.082353  ,  0.07450986],\n         ...,\n         [ 0.6       , -0.49019605, -0.67058825],\n         [ 0.54509807, -0.04313725, -0.1372549 ],\n         [ 0.92941177,  0.8666667 ,  0.8117647 ]],\n\n        [[ 0.69411767,  0.07450986,  0.05098045],\n         [ 0.6784314 ,  0.07450986,  0.06666672],\n         [ 0.6627451 ,  0.082353  ,  0.07450986],\n         ...,\n         [ 0.5686275 , -0.4980392 , -0.6784314 ],\n         [ 0.5686275 ,  0.03529418, -0.05882353],\n         [ 0.9529412 ,  0.8901961 ,  0.84313726]],\n\n        ...,\n\n        [[ 0.09019613, -0.01960784, -0.23137254],\n         [ 0.082353  , -0.02745098, -0.25490195],\n         [ 0.082353  , -0.02745098, -0.27058822],\n         ...,\n         [-0.73333335, -0.8117647 , -0.92156863],\n         [-0.7254902 , -0.827451  , -0.92941177],\n         [-0.69411767, -0.8039216 , -0.90588236]],\n\n        [[ 0.09019613, -0.01960784, -0.23137254],\n         [ 0.082353  , -0.02745098, -0.25490195],\n         [ 0.082353  , -0.02745098, -0.27058822],\n         ...,\n         [-0.67058825, -0.7490196 , -0.8666667 ],\n         [-0.6313726 , -0.7411765 , -0.8509804 ],\n         [-0.6       , -0.70980394, -0.8117647 ]],\n\n        [[ 0.082353  , -0.02745098, -0.23921567],\n         [ 0.07450986, -0.03529412, -0.26274508],\n         [ 0.082353  , -0.02745098, -0.27058822],\n         ...,\n         [-0.6784314 , -0.75686276, -0.8745098 ],\n         [-0.5764706 , -0.6784314 , -0.7882353 ],\n         [-0.58431375, -0.69411767, -0.79607844]]],\n\n\n       [[[-0.7411765 , -0.6862745 , -0.654902  ],\n         [-0.7411765 , -0.6862745 , -0.654902  ],\n         [-0.7411765 , -0.69411767, -0.654902  ],\n         ...,\n         [-0.75686276, -0.7254902 , -0.7254902 ],\n         [-0.6862745 , -0.64705884, -0.6392157 ],\n         [-0.6392157 , -0.58431375, -0.56078434]],\n\n        [[-0.69411767, -0.7254902 , -0.69411767],\n         [-0.7019608 , -0.7176471 , -0.6862745 ],\n         [-0.70980394, -0.7019608 , -0.6784314 ],\n         ...,\n         [-0.7411765 , -0.70980394, -0.70980394],\n         [-0.67058825, -0.6313726 , -0.6156863 ],\n         [-0.62352943, -0.5686275 , -0.54509807]],\n\n        [[-0.69411767, -0.84313726, -0.81960785],\n         [-0.6784314 , -0.8039216 , -0.7882353 ],\n         [-0.6862745 , -0.77254903, -0.77254903],\n         ...,\n         [-0.73333335, -0.69411767, -0.69411767],\n         [-0.6627451 , -0.62352943, -0.60784316],\n         [-0.6313726 , -0.5764706 , -0.54509807]],\n\n        ...,\n\n        [[ 0.27843142,  0.03529418, -0.11372548],\n         [ 0.27058828,  0.02745104, -0.12941176],\n         [ 0.21568632, -0.02745098, -0.17647058],\n         ...,\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ]],\n\n        [[ 0.2313726 , -0.01176471, -0.16862744],\n         [ 0.20784318, -0.03529412, -0.19215685],\n         [ 0.17647064, -0.06666666, -0.2235294 ],\n         ...,\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ]],\n\n        [[ 0.18431377, -0.05882353, -0.21568626],\n         [ 0.19215691, -0.05098039, -0.20784312],\n         [ 0.20784318, -0.03529412, -0.19215685],\n         ...,\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ]]],\n\n\n       ...,\n\n\n       [[[-0.67058825, -0.7882353 , -0.7176471 ],\n         [-0.64705884, -0.70980394, -0.67058825],\n         [-0.62352943, -0.6392157 , -0.6313726 ],\n         ...,\n         [-0.9137255 , -0.9137255 , -0.8980392 ],\n         [-0.9372549 , -0.9372549 , -0.92156863],\n         [-0.9137255 , -0.9137255 , -0.90588236]],\n\n        [[ 0.082353  , -0.08235294, -0.19999999],\n         [ 0.09803927, -0.04313725, -0.17647058],\n         [ 0.07450986, -0.03529412, -0.18431371],\n         ...,\n         [-0.94509804, -0.94509804, -0.92156863],\n         [-0.92156863, -0.92941177, -0.8980392 ],\n         [-0.92156863, -0.92156863, -0.8980392 ]],\n\n        [[ 0.00392163, -0.19999999, -0.44313723],\n         [ 0.07450986, -0.12941176, -0.38039213],\n         [ 0.09019613, -0.1372549 , -0.38823527],\n         ...,\n         [-0.94509804, -0.9529412 , -0.90588236],\n         [-0.9372549 , -0.94509804, -0.90588236],\n         [-0.9607843 , -0.96862745, -0.92941177]],\n\n        ...,\n\n        [[-0.18431371, -0.19215685, -0.20784312],\n         [-0.17647058, -0.18431371, -0.19999999],\n         [-0.17647058, -0.18431371, -0.19999999],\n         ...,\n         [-0.92941177, -0.9372549 , -0.8901961 ],\n         [-0.90588236, -0.9137255 , -0.85882354],\n         [-0.8980392 , -0.90588236, -0.8509804 ]],\n\n        [[-0.0745098 , -0.08235294, -0.09803921],\n         [-0.09019607, -0.09803921, -0.11372548],\n         [-0.14509803, -0.15294117, -0.16862744],\n         ...,\n         [-0.92941177, -0.9372549 , -0.8901961 ],\n         [-0.9372549 , -0.94509804, -0.88235295],\n         [-0.9137255 , -0.92156863, -0.8666667 ]],\n\n        [[ 0.19215691,  0.18431377,  0.1686275 ],\n         [-0.02745098, -0.03529412, -0.05098039],\n         [-0.21568626, -0.2235294 , -0.23921567],\n         ...,\n         [-0.9137255 , -0.92156863, -0.8745098 ],\n         [-0.9137255 , -0.92156863, -0.85882354],\n         [-0.9137255 , -0.92156863, -0.8745098 ]]],\n\n\n       [[[ 0.7647059 ,  0.70980394,  0.5686275 ],\n         [ 0.7647059 ,  0.70980394,  0.5686275 ],\n         [ 0.7647059 ,  0.70980394,  0.5686275 ],\n         ...,\n         [-0.58431375, -0.60784316, -0.6392157 ],\n         [-0.5764706 , -0.6       , -0.6392157 ],\n         [-0.5764706 , -0.6       , -0.6313726 ]],\n\n        [[ 0.7647059 ,  0.70980394,  0.5686275 ],\n         [ 0.7647059 ,  0.70980394,  0.5686275 ],\n         [ 0.7647059 ,  0.70980394,  0.5686275 ],\n         ...,\n         [-0.56078434, -0.58431375, -0.6313726 ],\n         [-0.5529412 , -0.5764706 , -0.62352943],\n         [-0.5529412 , -0.5764706 , -0.62352943]],\n\n        [[ 0.77254903,  0.7176471 ,  0.5764706 ],\n         [ 0.77254903,  0.7176471 ,  0.5764706 ],\n         [ 0.7647059 ,  0.70980394,  0.5686275 ],\n         ...,\n         [-0.56078434, -0.58431375, -0.64705884],\n         [-0.56078434, -0.58431375, -0.64705884],\n         [-0.56078434, -0.58431375, -0.64705884]],\n\n        ...,\n\n        [[-0.03529412, -0.04313725, -0.04313725],\n         [-0.23921567, -0.24705881, -0.24705881],\n         [-0.2235294 , -0.23137254, -0.2235294 ],\n         ...,\n         [-0.8980392 , -0.90588236, -0.92941177],\n         [-0.827451  , -0.8509804 , -0.8901961 ],\n         [-0.8509804 , -0.8666667 , -0.8901961 ]],\n\n        [[-0.2862745 , -0.2862745 , -0.27843136],\n         [-0.30196077, -0.30196077, -0.30196077],\n         [-0.2862745 , -0.2862745 , -0.27058822],\n         ...,\n         [-0.5686275 , -0.5764706 , -0.58431375],\n         [-0.5372549 , -0.56078434, -0.58431375],\n         [-0.5764706 , -0.5921569 , -0.60784316]],\n\n        [[-0.27058822, -0.27058822, -0.27058822],\n         [-0.2862745 , -0.2862745 , -0.2862745 ],\n         [-0.25490195, -0.25490195, -0.24705881],\n         ...,\n         [-0.8117647 , -0.827451  , -0.79607844],\n         [-0.81960785, -0.8509804 , -0.827451  ],\n         [-0.8509804 , -0.8666667 , -0.8666667 ]]],\n\n\n       [[[-0.78039217, -0.64705884, -0.58431375],\n         [-0.827451  , -0.69411767, -0.6313726 ],\n         [-0.90588236, -0.7882353 , -0.73333335],\n         ...,\n         [-0.75686276, -0.84313726, -0.96862745],\n         [-0.73333335, -0.827451  , -0.9607843 ],\n         [-0.7490196 , -0.8509804 , -0.94509804]],\n\n        [[-0.7647059 , -0.6313726 , -0.5686275 ],\n         [-0.8117647 , -0.6784314 , -0.62352943],\n         [-0.8901961 , -0.7647059 , -0.7176471 ],\n         ...,\n         [-0.75686276, -0.84313726, -0.96862745],\n         [-0.7411765 , -0.827451  , -0.9607843 ],\n         [-0.7490196 , -0.8509804 , -0.9529412 ]],\n\n        [[-0.7647059 , -0.6313726 , -0.5686275 ],\n         [-0.8039216 , -0.67058825, -0.6156863 ],\n         [-0.88235295, -0.75686276, -0.70980394],\n         ...,\n         [-0.75686276, -0.84313726, -0.96862745],\n         [-0.7411765 , -0.827451  , -0.9607843 ],\n         [-0.7254902 , -0.84313726, -0.9529412 ]],\n\n        ...,\n\n        [[-0.05882353, -0.19215685, -0.1372549 ],\n         [ 0.14509809,  0.02745104,  0.10588241],\n         [ 0.48235297,  0.3803922 ,  0.47450984],\n         ...,\n         [ 0.09803927,  0.06666672,  0.05882359],\n         [ 0.082353  ,  0.06666672,  0.04313731],\n         [ 0.19215691,  0.14509809,  0.1686275 ]],\n\n        [[-0.1607843 , -0.10588235,  0.06666672],\n         [ 0.0196079 ,  0.05882359,  0.254902  ],\n         [ 0.34901965,  0.3803922 ,  0.5764706 ],\n         ...,\n         [ 0.3411765 ,  0.19215691,  0.19215691],\n         [ 0.2313726 ,  0.12156868,  0.11372554],\n         [ 0.20000005,  0.12941182,  0.14509809]],\n\n        [[-0.00392157,  0.12156868,  0.3411765 ],\n         [ 0.2941177 ,  0.3803922 ,  0.58431375],\n         [ 0.60784316,  0.64705884,  0.8352941 ],\n         ...,\n         [ 0.23921573,  0.14509809,  0.16078436],\n         [ 0.07450986,  0.05882359,  0.06666672],\n         [ 0.082353  ,  0.06666672,  0.09803927]]]], dtype=float32)>,\n  7: <tf.Tensor: shape=(64, 64, 64, 3), dtype=float32, numpy=\narray([[[[ 0.7019608 ,  0.73333335,  0.8039216 ],\n         [ 0.7019608 ,  0.73333335,  0.8039216 ],\n         [ 0.7019608 ,  0.73333335,  0.8039216 ],\n         ...,\n         [ 0.78039217,  0.78039217,  0.81960785],\n         [ 0.7254902 ,  0.7647059 ,  0.7882353 ],\n         [ 0.7254902 ,  0.78039217,  0.8117647 ]],\n\n        [[ 0.7019608 ,  0.73333335,  0.8039216 ],\n         [ 0.7019608 ,  0.73333335,  0.8039216 ],\n         [ 0.7019608 ,  0.73333335,  0.8039216 ],\n         ...,\n         [ 0.78039217,  0.78039217,  0.81960785],\n         [ 0.7254902 ,  0.7647059 ,  0.7882353 ],\n         [ 0.7254902 ,  0.78039217,  0.8117647 ]],\n\n        [[ 0.7019608 ,  0.73333335,  0.8039216 ],\n         [ 0.7019608 ,  0.73333335,  0.8039216 ],\n         [ 0.7019608 ,  0.73333335,  0.8039216 ],\n         ...,\n         [ 0.78039217,  0.78039217,  0.81960785],\n         [ 0.7254902 ,  0.7647059 ,  0.7882353 ],\n         [ 0.7254902 ,  0.78039217,  0.8117647 ]],\n\n        ...,\n\n        [[ 0.75686276,  0.7882353 ,  0.85882354],\n         [ 0.75686276,  0.7882353 ,  0.85882354],\n         [ 0.75686276,  0.7882353 ,  0.85882354],\n         ...,\n         [-0.84313726, -0.84313726, -0.84313726],\n         [-0.8901961 , -0.8901961 , -0.8901961 ],\n         [-0.8901961 , -0.8901961 , -0.8901961 ]],\n\n        [[ 0.75686276,  0.7882353 ,  0.85882354],\n         [ 0.75686276,  0.7882353 ,  0.85882354],\n         [ 0.75686276,  0.7882353 ,  0.85882354],\n         ...,\n         [-0.85882354, -0.85882354, -0.85882354],\n         [-0.8745098 , -0.8745098 , -0.8745098 ],\n         [-0.8980392 , -0.8980392 , -0.8980392 ]],\n\n        [[ 0.7490196 ,  0.78039217,  0.8509804 ],\n         [ 0.7490196 ,  0.78039217,  0.8509804 ],\n         [ 0.75686276,  0.7882353 ,  0.85882354],\n         ...,\n         [-0.8745098 , -0.8745098 , -0.8745098 ],\n         [-0.8745098 , -0.8745098 , -0.8745098 ],\n         [-0.90588236, -0.90588236, -0.90588236]]],\n\n\n       [[[ 0.15294123, -0.11372548, -0.27843136],\n         [ 0.10588241, -0.1372549 , -0.27843136],\n         [-0.01960784, -0.19215685, -0.27058822],\n         ...,\n         [-0.09019607, -0.32549018, -0.40392154],\n         [-0.10588235, -0.34117645, -0.36470586],\n         [ 0.02745104, -0.19215685, -0.25490195]],\n\n        [[ 0.15294123, -0.11372548, -0.27843136],\n         [ 0.10588241, -0.1372549 , -0.27843136],\n         [-0.01960784, -0.19215685, -0.27058822],\n         ...,\n         [-0.09019607, -0.32549018, -0.40392154],\n         [-0.10588235, -0.34117645, -0.36470586],\n         [ 0.02745104, -0.19215685, -0.25490195]],\n\n        [[ 0.15294123, -0.11372548, -0.2862745 ],\n         [ 0.10588241, -0.1372549 , -0.27843136],\n         [-0.01960784, -0.19215685, -0.27843136],\n         ...,\n         [-0.09803921, -0.3333333 , -0.41176468],\n         [-0.10588235, -0.34117645, -0.36470586],\n         [ 0.03529418, -0.18431371, -0.25490195]],\n\n        ...,\n\n        [[-0.27843136, -0.5137255 , -0.6       ],\n         [-0.3490196 , -0.5529412 , -0.64705884],\n         [-0.1372549 , -0.3098039 , -0.41176468],\n         ...,\n         [-0.45098037, -0.6313726 , -0.6784314 ],\n         [-0.4980392 , -0.64705884, -0.69411767],\n         [-0.58431375, -0.654902  , -0.69411767]],\n\n        [[-0.32549018, -0.54509807, -0.6392157 ],\n         [-0.34117645, -0.5372549 , -0.6313726 ],\n         [-0.09019607, -0.24705881, -0.3333333 ],\n         ...,\n         [-0.30196077, -0.46666664, -0.5137255 ],\n         [-0.12156862, -0.25490195, -0.2862745 ],\n         [-0.35686272, -0.4352941 , -0.4588235 ]],\n\n        [[-0.31764704, -0.52156866, -0.64705884],\n         [-0.29411763, -0.46666664, -0.56078434],\n         [ 0.00392163, -0.14509803, -0.20784312],\n         ...,\n         [-0.3490196 , -0.47450978, -0.52156866],\n         [-0.44313723, -0.5294118 , -0.54509807],\n         [-0.3960784 , -0.47450978, -0.49019605]]],\n\n\n       [[[-0.0745098 ,  0.45098042,  0.49803925],\n         [ 0.0196079 ,  0.45098042,  0.56078434],\n         [ 0.0196079 ,  0.3411765 ,  0.5294118 ],\n         ...,\n         [-0.67058825, -0.15294117, -0.17647058],\n         [-0.5294118 , -0.00392157,  0.02745104],\n         [-0.5921569 , -0.06666666, -0.05882353]],\n\n        [[-0.1372549 ,  0.427451  ,  0.4431373 ],\n         [-0.01176471,  0.45882356,  0.54509807],\n         [ 0.03529418,  0.37254906,  0.5529412 ],\n         ...,\n         [-0.5529412 , -0.04313725, -0.05882353],\n         [-0.56078434, -0.04313725, -0.01176471],\n         [-0.64705884, -0.09803921, -0.09803921]],\n\n        [[-0.23137254,  0.39607847,  0.37254906],\n         [-0.0745098 ,  0.45882356,  0.5058824 ],\n         [ 0.02745104,  0.41960788,  0.56078434],\n         ...,\n         [-0.56078434, -0.0745098 , -0.08235294],\n         [-0.654902  , -0.1607843 , -0.11372548],\n         [-0.6784314 , -0.12941176, -0.12941176]],\n\n        ...,\n\n        [[-0.1372549 ,  0.4039216 ,  0.38823533],\n         [-0.04313725,  0.37254906,  0.4039216 ],\n         [ 0.12156868,  0.49803925,  0.5372549 ],\n         ...,\n         [ 0.6313726 , -0.14509803, -0.4588235 ],\n         [ 0.6392157 , -0.12941176, -0.44313723],\n         [ 0.654902  , -0.06666666, -0.372549  ]],\n\n        [[-0.01960784,  0.43529415,  0.43529415],\n         [ 0.082353  ,  0.4039216 ,  0.45098042],\n         [ 0.20784318,  0.5137255 ,  0.56078434],\n         ...,\n         [ 0.6392157 , -0.12941176, -0.4352941 ],\n         [ 0.6392157 , -0.12156862, -0.42745095],\n         [ 0.6313726 , -0.08235294, -0.3960784 ]],\n\n        [[ 0.18431377,  0.5372549 ,  0.56078434],\n         [ 0.24705887,  0.5058824 ,  0.56078434],\n         [ 0.2313726 ,  0.5137255 ,  0.56078434],\n         ...,\n         [ 0.654902  , -0.09019607, -0.40392154],\n         [ 0.6627451 , -0.08235294, -0.40392154],\n         [ 0.6392157 , -0.06666666, -0.38039213]]],\n\n\n       ...,\n\n\n       [[[-0.41960782, -0.6       , -0.8666667 ],\n         [-0.41960782, -0.6       , -0.8666667 ],\n         [-0.41960782, -0.6       , -0.8666667 ],\n         ...,\n         [ 0.43529415, -0.32549018, -0.77254903],\n         [ 0.70980394, -0.03529412, -0.5372549 ],\n         [ 0.7411765 ,  0.04313731, -0.5137255 ]],\n\n        [[-0.41960782, -0.6       , -0.8666667 ],\n         [-0.41960782, -0.6       , -0.8666667 ],\n         [-0.41960782, -0.6       , -0.8666667 ],\n         ...,\n         [ 0.41960788, -0.34117645, -0.7882353 ],\n         [ 0.69411767, -0.04313725, -0.5529412 ],\n         [ 0.73333335,  0.03529418, -0.5137255 ]],\n\n        [[-0.41960782, -0.6       , -0.8666667 ],\n         [-0.41960782, -0.6       , -0.8666667 ],\n         [-0.41960782, -0.6       , -0.8666667 ],\n         ...,\n         [ 0.41960788, -0.34117645, -0.7882353 ],\n         [ 0.69411767, -0.05098039, -0.5529412 ],\n         [ 0.7411765 ,  0.04313731, -0.5137255 ]],\n\n        ...,\n\n        [[ 0.7411765 ,  0.02745104, -0.654902  ],\n         [ 0.7411765 ,  0.02745104, -0.654902  ],\n         [ 0.7411765 ,  0.02745104, -0.654902  ],\n         ...,\n         [-0.6784314 , -0.7490196 , -0.90588236],\n         [-0.69411767, -0.75686276, -0.88235295],\n         [-0.67058825, -0.75686276, -0.8352941 ]],\n\n        [[ 0.8352941 ,  0.07450986, -0.6862745 ],\n         [ 0.8352941 ,  0.07450986, -0.6862745 ],\n         [ 0.8352941 ,  0.07450986, -0.6862745 ],\n         ...,\n         [-0.6862745 , -0.75686276, -0.88235295],\n         [-0.7176471 , -0.78039217, -0.92941177],\n         [-0.67058825, -0.7490196 , -0.8666667 ]],\n\n        [[ 0.8901961 ,  0.09019613, -0.73333335],\n         [ 0.8901961 ,  0.09019613, -0.73333335],\n         [ 0.8901961 ,  0.09019613, -0.73333335],\n         ...,\n         [-0.70980394, -0.78039217, -0.8980392 ],\n         [-0.73333335, -0.8039216 , -0.9137255 ],\n         [-0.75686276, -0.827451  , -0.9137255 ]]],\n\n\n       [[[-0.27058822,  0.58431375,  0.654902  ],\n         [-0.8901961 ,  0.254902  ,  0.5294118 ],\n         [-0.00392157,  0.6313726 ,  0.7411765 ],\n         ...,\n         [ 0.77254903,  0.082353  ,  0.22352946],\n         [ 0.88235295,  0.12941182,  0.3411765 ],\n         [ 1.        , -0.05098039,  0.23921573]],\n\n        [[-0.40392154,  0.5137255 ,  0.5686275 ],\n         [-0.8509804 ,  0.254902  ,  0.5372549 ],\n         [ 0.082353  ,  0.6627451 ,  0.77254903],\n         ...,\n         [ 0.79607844,  0.09803927,  0.23921573],\n         [ 0.85882354,  0.09803927,  0.30980396],\n         [ 1.        , -0.01960784,  0.24705887]],\n\n        [[-0.5137255 ,  0.4901961 ,  0.54509807],\n         [-0.7882353 ,  0.254902  ,  0.5529412 ],\n         [ 0.20784318,  0.69411767,  0.8039216 ],\n         ...,\n         [ 0.8117647 ,  0.09803927,  0.254902  ],\n         [ 0.8509804 ,  0.07450986,  0.2941177 ],\n         [ 0.9843137 , -0.01176471,  0.23921573]],\n\n        ...,\n\n        [[-0.69411767, -0.78039217, -0.7490196 ],\n         [-0.7019608 , -0.7882353 , -0.75686276],\n         [-0.6862745 , -0.77254903, -0.7411765 ],\n         ...,\n         [-0.4823529 , -0.5294118 , -0.4823529 ],\n         [-0.5137255 , -0.54509807, -0.5058824 ],\n         [-0.36470586, -0.44313723, -0.46666664]],\n\n        [[-0.7019608 , -0.79607844, -0.7647059 ],\n         [-0.69411767, -0.7882353 , -0.75686276],\n         [-0.7019608 , -0.79607844, -0.7647059 ],\n         ...,\n         [-0.5294118 , -0.5686275 , -0.52156866],\n         [-0.5058824 , -0.54509807, -0.4980392 ],\n         [-0.5137255 , -0.5529412 , -0.52156866]],\n\n        [[-0.7019608 , -0.79607844, -0.7647059 ],\n         [-0.7019608 , -0.79607844, -0.7647059 ],\n         [-0.7019608 , -0.79607844, -0.7647059 ],\n         ...,\n         [-0.5372549 , -0.5764706 , -0.5294118 ],\n         [-0.56078434, -0.6       , -0.5529412 ],\n         [-0.5921569 , -0.5921569 , -0.54509807]]],\n\n\n       [[[ 0.88235295,  0.9137255 ,  0.9843137 ],\n         [ 0.88235295,  0.9137255 ,  0.9843137 ],\n         [ 0.88235295,  0.9137255 ,  0.9843137 ],\n         ...,\n         [ 0.88235295,  0.92156863,  0.9529412 ],\n         [ 0.88235295,  0.92156863,  0.9529412 ],\n         [ 0.88235295,  0.92156863,  0.9529412 ]],\n\n        [[ 0.88235295,  0.9137255 ,  0.9843137 ],\n         [ 0.88235295,  0.9137255 ,  0.9843137 ],\n         [ 0.88235295,  0.9137255 ,  0.9843137 ],\n         ...,\n         [ 0.88235295,  0.92156863,  0.9529412 ],\n         [ 0.88235295,  0.92156863,  0.9529412 ],\n         [ 0.88235295,  0.92156863,  0.9529412 ]],\n\n        [[ 0.88235295,  0.9137255 ,  0.9843137 ],\n         [ 0.88235295,  0.9137255 ,  0.9843137 ],\n         [ 0.88235295,  0.9137255 ,  0.9843137 ],\n         ...,\n         [ 0.88235295,  0.92156863,  0.9529412 ],\n         [ 0.88235295,  0.92156863,  0.9529412 ],\n         [ 0.88235295,  0.92156863,  0.9529412 ]],\n\n        ...,\n\n        [[ 0.9137255 ,  0.9529412 ,  0.9607843 ],\n         [ 0.9137255 ,  0.94509804,  0.96862745],\n         [ 0.90588236,  0.94509804,  0.9764706 ],\n         ...,\n         [ 0.69411767,  0.62352943,  0.6392157 ],\n         [ 0.7019608 ,  0.6392157 ,  0.64705884],\n         [ 0.7411765 ,  0.654902  ,  0.6627451 ]],\n\n        [[ 0.8901961 ,  0.92941177,  0.99215686],\n         [ 0.8666667 ,  0.90588236,  0.9764706 ],\n         [ 0.78039217,  0.8117647 ,  0.9137255 ],\n         ...,\n         [ 0.7019608 ,  0.62352943,  0.62352943],\n         [ 0.7411765 ,  0.6627451 ,  0.67058825],\n         [ 0.6862745 ,  0.60784316,  0.6       ]],\n\n        [[ 0.827451  ,  0.8509804 ,  0.96862745],\n         [ 0.73333335,  0.75686276,  0.8901961 ],\n         [ 0.67058825,  0.69411767,  0.84313726],\n         ...,\n         [ 0.7019608 ,  0.6156863 ,  0.60784316],\n         [ 0.7254902 ,  0.6392157 ,  0.6313726 ],\n         [ 0.6627451 ,  0.5764706 ,  0.56078434]]]], dtype=float32)>\n}) with an unsupported type (<class 'tensorflow.python.distribute.values.PerReplica'>) to a Tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HlKYdko3z9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for step, (X1, X2) in enumerate(pbar):\n",
        "    d_loss, g_loss, fake = train_on_batch(X1, X2)\n",
        "    pbar.set_postfix({\"g_loss\": g_loss.numpy(), \"d_loss\": d_loss.numpy()})\n",
        "    if step == 200000 // batch_size - 1:\n",
        "        fake_img = fake # 末尾だと端数が出るため"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygKvbrpmP84h",
        "colab_type": "code",
        "outputId": "7e3091a7-e9ac-452b-a6b5-a65a62c795ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# お持ち帰り用\n",
        "!zip -r celeba_out.zip celeba_out/*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: celeba_out/epoch_0000.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0001.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0002.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0003.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0004.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0005.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0006.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0007.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0008.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0009.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0010.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0011.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0012.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0013.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0014.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0015.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0016.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0017.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0018.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0019.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0020.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0021.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0022.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0023.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0024.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0025.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0026.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0027.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0028.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0029.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0030.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0031.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0032.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0033.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0034.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0035.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0036.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0037.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0038.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0039.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0040.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0041.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0042.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0043.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0044.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0045.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0046.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0047.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0048.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0049.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0050.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0051.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0052.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0053.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0054.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0055.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0056.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0057.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0058.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0059.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0060.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0061.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0062.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0063.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0064.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0065.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0066.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0067.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0068.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0069.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0070.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0071.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0072.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0073.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0074.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0075.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0076.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0077.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0078.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0079.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0080.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0081.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0082.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0083.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0084.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0085.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0086.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0087.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0088.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0089.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0090.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0091.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0092.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0093.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0094.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0095.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0096.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0097.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0098.png (deflated 0%)\n",
            "  adding: celeba_out/epoch_0099.png (deflated 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xr6nUsRQeIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"celeba_out.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}